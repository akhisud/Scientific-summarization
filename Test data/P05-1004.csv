Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	1
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	consistency classifying similar words categories.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	supersenses synonyms combined determine supersense.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	names descriptions noun lex-files shown Table 1.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita et al.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	co-occurrence window 500 words designed approximate average document length.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	measure found successful entropy conditional distribution surrounding words given noun.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Specificity ordering necessary step building noun hierarchy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, approach clearly cannot build hierarchy alone.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	instance, entity less frequent many concepts subsumes.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	technique used approach supersense tagging.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	developed efficient algorithm estimating model hierarchical training data.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	examples test sets given Table 2 supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	components sizes including punctuation given Table 3.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	LDC recently released English Gigaword corpus includes corpora listed above.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	rest pipeline described next section.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	key parameters context extraction method similarity measure used compare context vectors.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	describe shallow pipeline detail below.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, morphological smoothing still produces better results practice.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	6.1 Part Speech Tagging Chunking.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	6.2 Morphological Analysis.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	morpha wide coverage – nearly 100% across passes.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	global list used determine word already attached.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	types grammatical relation extracted SEXTANT shown Table 4.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	corresponds assuming right-branching noun compounds.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Within NP NP PP heads remain unattached.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	corresponds assuming right-branching PP attachment.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	phrase NP head remains unattached.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Tense Determination rightmost verb VP considered head.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	VP initially categorised active.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	head verb form VP becomes attributive.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	noun heads either side VPs remain unattached.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	example, antigen subject represent.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	VP classed active phrase NP direct object (dobj) relation created.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	VP classed passive phrase NP subject (subj) relation created.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	following phrase PP indirect object (iobj) relation created.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, SEXTANT always attaches PP previous phrase.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	progressive verb appears determiner quantifier considered noun.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	supersense guessing rules given Table 5.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	none rules match, default supersense artifact assigned.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	experiments described consider range options parameters.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	fact, experiments quick run able exhaustively test many combinations parameters.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	experimented 200 voting extracted synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	several ways weight synonym’s contribution.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	simplest approach would give synonym weight.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Another approach use scores returned similarity system.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Alternatively, weights use ranking extracted synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	options considered below.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	final issue deal polysemy.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	experiments performed considering possible configurations parameters described above.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	initial weight could divided number supersenses share weight (SHARED).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	weight could also divided rank (RANK) penalise supersenses list.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	extracted synonyms filtered contributing vote supersense(s).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	next question many synonyms considered.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	top performing configurations used 50 synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, filter turned make little difference.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Finally, need decide use similarity measure fall-back guessing rules.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	determined looking frequency number attributes unknown word.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	surprisingly, similarity system works better guessing rules information all.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	results summarised Table 6.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Table 7 shows breakdown performance supersense.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	columns show number instances supersense precision, recall f-score measures percentages.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	frequent supersenses test sets person, attribute act.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	factors conducive extracting reliable synonyms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	alternative approach worth exploring create context vectors supersense categories compare words.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	advantage producing much smaller number vectors compare against.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	question becomes construct vectors supersenses.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	obvious solution sum context vectors across words supersense.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Also, questions arise construction vectors.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	words multiple supersenses handled?	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, given sparseness data may leave large context vectors.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	number problems system currently handle.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Further, similarity system currently incorporate multi-word terms.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	overcome using synonyms last word multi-word term.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Supersense Tagging Unknown Nouns using Semantic Similarity	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	consistency classifying similar words categories.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	paper describes unsupervised approach supersense tagging require annotated sentences.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	supersenses synonyms combined determine supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	names descriptions noun lex-files shown Table 1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita et al.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	co-occurrence window 500 words designed approximate average document length.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	measure found successful entropy conditional distribution surrounding words given noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Specificity ordering necessary step building noun hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, approach clearly cannot build hierarchy alone.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	instance, entity less frequent many concepts subsumes.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	technique used approach supersense tagging.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	1
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	developed efficient algorithm estimating model hierarchical training data.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	evaluation use exactly test sets Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	examples test sets given Table 2 supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	components sizes including punctuation given Table 3.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	LDC recently released English Gigaword corpus includes corpora listed above.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	rest pipeline described next section.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	vector-space models headword represented vector frequency counts recording contexts appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	key parameters context extraction method similarity measure used compare context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	describe shallow pipeline detail below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, morphological smoothing still produces better results practice.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	6.1 Part Speech Tagging Chunking.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	6.2 Morphological Analysis.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	morpha wide coverage – nearly 100% across passes.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	global list used determine word already attached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	types grammatical relation extracted SEXTANT shown Table 4.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	corresponds assuming right-branching noun compounds.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Within NP NP PP heads remain unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	corresponds assuming right-branching PP attachment.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	phrase NP head remains unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Tense Determination rightmost verb VP considered head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	VP initially categorised active.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	head verb form VP becomes attributive.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	noun heads either side VPs remain unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	remaining three passes attach verb heads either subjects objects depending voice VP.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	example, antigen subject represent.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	VP classed active phrase NP direct object (dobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	VP classed passive phrase NP subject (subj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	following phrase PP indirect object (iobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, SEXTANT always attaches PP previous phrase.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	progressive verb appears determiner quantifier considered noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	supersense guessing rules given Table 5.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	none rules match, default supersense artifact assigned.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	extracted synonym votes one supersenses appear WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	experiments described consider range options parameters.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	fact, experiments quick run able exhaustively test many combinations parameters.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	experimented 200 voting extracted synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	several ways weight synonym’s contribution.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	simplest approach would give synonym weight.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Another approach use scores returned similarity system.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Alternatively, weights use ranking extracted synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	options considered below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	final issue deal polysemy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	experiments performed considering possible configurations parameters described above.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	initial weight could divided number supersenses share weight (SHARED).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	weight could also divided rank (RANK) penalise supersenses list.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	extracted synonyms filtered contributing vote supersense(s).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	next question many synonyms considered.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	top performing configurations used 50 synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, filter turned make little difference.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Finally, need decide use similarity measure fall-back guessing rules.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	determined looking frequency number attributes unknown word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	surprisingly, similarity system works better guessing rules information all.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	results summarised Table 6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Table 7 shows breakdown performance supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	columns show number instances supersense precision, recall f-score measures percentages.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	frequent supersenses test sets person, attribute act.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	factors conducive extracting reliable synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	alternative approach worth exploring create context vectors supersense categories compare words.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	advantage producing much smaller number vectors compare against.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	question becomes construct vectors supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	obvious solution sum context vectors across words supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Also, questions arise construction vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	words multiple supersenses handled?	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, given sparseness data may leave large context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	number problems system currently handle.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Further, similarity system currently incorporate multi-word terms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	overcome using synonyms last word multi-word term.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	consistency classifying similar words categories.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	supersenses synonyms combined determine supersense.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	names descriptions noun lex-files shown Table 1.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita et al.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	co-occurrence window 500 words designed approximate average document length.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	measure found successful entropy conditional distribution surrounding words given noun.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Specificity ordering necessary step building noun hierarchy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, approach clearly cannot build hierarchy alone.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	instance, entity less frequent many concepts subsumes.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	technique used approach supersense tagging.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	developed efficient algorithm estimating model hierarchical training data.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	examples test sets given Table 2 supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	components sizes including punctuation given Table 3.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	LDC recently released English Gigaword corpus includes corpora listed above.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	rest pipeline described next section.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	key parameters context extraction method similarity measure used compare context vectors.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	describe shallow pipeline detail below.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, morphological smoothing still produces better results practice.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	6.1 Part Speech Tagging Chunking.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	6.2 Morphological Analysis.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	morpha wide coverage – nearly 100% across passes.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	global list used determine word already attached.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	types grammatical relation extracted SEXTANT shown Table 4.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	corresponds assuming right-branching noun compounds.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Within NP NP PP heads remain unattached.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	corresponds assuming right-branching PP attachment.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	phrase NP head remains unattached.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Tense Determination rightmost verb VP considered head.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	VP initially categorised active.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	head verb form VP becomes attributive.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	noun heads either side VPs remain unattached.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	example, antigen subject represent.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	VP classed active phrase NP direct object (dobj) relation created.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	VP classed passive phrase NP subject (subj) relation created.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	following phrase PP indirect object (iobj) relation created.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, SEXTANT always attaches PP previous phrase.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	progressive verb appears determiner quantifier considered noun.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	1
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	supersense guessing rules given Table 5.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	none rules match, default supersense artifact assigned.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	experiments described consider range options parameters.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	fact, experiments quick run able exhaustively test many combinations parameters.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	experimented 200 voting extracted synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	several ways weight synonym’s contribution.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	simplest approach would give synonym weight.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Another approach use scores returned similarity system.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Alternatively, weights use ranking extracted synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	options considered below.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	final issue deal polysemy.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	experiments performed considering possible configurations parameters described above.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	initial weight could divided number supersenses share weight (SHARED).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	weight could also divided rank (RANK) penalise supersenses list.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	extracted synonyms filtered contributing vote supersense(s).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	next question many synonyms considered.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	top performing configurations used 50 synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, filter turned make little difference.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Finally, need decide use similarity measure fall-back guessing rules.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	determined looking frequency number attributes unknown word.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	surprisingly, similarity system works better guessing rules information all.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	results summarised Table 6.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Table 7 shows breakdown performance supersense.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	columns show number instances supersense precision, recall f-score measures percentages.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	frequent supersenses test sets person, attribute act.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	factors conducive extracting reliable synonyms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	alternative approach worth exploring create context vectors supersense categories compare words.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	advantage producing much smaller number vectors compare against.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	question becomes construct vectors supersenses.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	obvious solution sum context vectors across words supersense.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Also, questions arise construction vectors.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	words multiple supersenses handled?	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, given sparseness data may leave large context vectors.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	number problems system currently handle.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Further, similarity system currently incorporate multi-word terms.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	overcome using synonyms last word multi-word term.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	1
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	consistency classifying similar words categories.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	supersenses synonyms combined determine supersense.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	names descriptions noun lex-files shown Table 1.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita et al.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	co-occurrence window 500 words designed approximate average document length.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	measure found successful entropy conditional distribution surrounding words given noun.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Specificity ordering necessary step building noun hierarchy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, approach clearly cannot build hierarchy alone.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	instance, entity less frequent many concepts subsumes.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	technique used approach supersense tagging.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	developed efficient algorithm estimating model hierarchical training data.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	examples test sets given Table 2 supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	components sizes including punctuation given Table 3.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	LDC recently released English Gigaword corpus includes corpora listed above.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	rest pipeline described next section.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	key parameters context extraction method similarity measure used compare context vectors.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	describe shallow pipeline detail below.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, morphological smoothing still produces better results practice.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	6.1 Part Speech Tagging Chunking.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	6.2 Morphological Analysis.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	morpha wide coverage – nearly 100% across passes.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	global list used determine word already attached.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	types grammatical relation extracted SEXTANT shown Table 4.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	corresponds assuming right-branching noun compounds.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Within NP NP PP heads remain unattached.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	corresponds assuming right-branching PP attachment.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	phrase NP head remains unattached.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Tense Determination rightmost verb VP considered head.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	VP initially categorised active.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	head verb form VP becomes attributive.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	noun heads either side VPs remain unattached.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	example, antigen subject represent.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	VP classed active phrase NP direct object (dobj) relation created.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	VP classed passive phrase NP subject (subj) relation created.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	following phrase PP indirect object (iobj) relation created.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, SEXTANT always attaches PP previous phrase.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	progressive verb appears determiner quantifier considered noun.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	supersense guessing rules given Table 5.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	none rules match, default supersense artifact assigned.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	experiments described consider range options parameters.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	fact, experiments quick run able exhaustively test many combinations parameters.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	experimented 200 voting extracted synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	several ways weight synonym’s contribution.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	simplest approach would give synonym weight.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Another approach use scores returned similarity system.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Alternatively, weights use ranking extracted synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	options considered below.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	final issue deal polysemy.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	experiments performed considering possible configurations parameters described above.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	initial weight could divided number supersenses share weight (SHARED).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	weight could also divided rank (RANK) penalise supersenses list.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	extracted synonyms filtered contributing vote supersense(s).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	next question many synonyms considered.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	top performing configurations used 50 synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, filter turned make little difference.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Finally, need decide use similarity measure fall-back guessing rules.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	determined looking frequency number attributes unknown word.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	surprisingly, similarity system works better guessing rules information all.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	results summarised Table 6.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Table 7 shows breakdown performance supersense.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	columns show number instances supersense precision, recall f-score measures percentages.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	frequent supersenses test sets person, attribute act.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	factors conducive extracting reliable synonyms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	alternative approach worth exploring create context vectors supersense categories compare words.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	advantage producing much smaller number vectors compare against.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	question becomes construct vectors supersenses.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	obvious solution sum context vectors across words supersense.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Also, questions arise construction vectors.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	words multiple supersenses handled?	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, given sparseness data may leave large context vectors.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	number problems system currently handle.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Further, similarity system currently incorporate multi-word terms.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	overcome using synonyms last word multi-word term.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	consistency classifying similar words categories.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	supersenses synonyms combined determine supersense.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	names descriptions noun lex-files shown Table 1.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita et al.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	co-occurrence window 500 words designed approximate average document length.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	measure found successful entropy conditional distribution surrounding words given noun.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Specificity ordering necessary step building noun hierarchy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, approach clearly cannot build hierarchy alone.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	instance, entity less frequent many concepts subsumes.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	technique used approach supersense tagging.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	developed efficient algorithm estimating model hierarchical training data.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	examples test sets given Table 2 supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	components sizes including punctuation given Table 3.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	LDC recently released English Gigaword corpus includes corpora listed above.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	rest pipeline described next section.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	key parameters context extraction method similarity measure used compare context vectors.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	describe shallow pipeline detail below.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, morphological smoothing still produces better results practice.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	6.1 Part Speech Tagging Chunking.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	6.2 Morphological Analysis.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	morpha wide coverage – nearly 100% across passes.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	global list used determine word already attached.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	types grammatical relation extracted SEXTANT shown Table 4.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	corresponds assuming right-branching noun compounds.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Within NP NP PP heads remain unattached.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	corresponds assuming right-branching PP attachment.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	phrase NP head remains unattached.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Tense Determination rightmost verb VP considered head.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	VP initially categorised active.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	head verb form VP becomes attributive.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	noun heads either side VPs remain unattached.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	example, antigen subject represent.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	VP classed active phrase NP direct object (dobj) relation created.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	VP classed passive phrase NP subject (subj) relation created.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	following phrase PP indirect object (iobj) relation created.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, SEXTANT always attaches PP previous phrase.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	progressive verb appears determiner quantifier considered noun.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	1
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	supersense guessing rules given Table 5.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	none rules match, default supersense artifact assigned.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	experiments described consider range options parameters.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	fact, experiments quick run able exhaustively test many combinations parameters.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	experimented 200 voting extracted synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	several ways weight synonym’s contribution.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	simplest approach would give synonym weight.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Another approach use scores returned similarity system.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Alternatively, weights use ranking extracted synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	options considered below.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	final issue deal polysemy.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	experiments performed considering possible configurations parameters described above.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	initial weight could divided number supersenses share weight (SHARED).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	weight could also divided rank (RANK) penalise supersenses list.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	extracted synonyms filtered contributing vote supersense(s).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	next question many synonyms considered.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	top performing configurations used 50 synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, filter turned make little difference.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Finally, need decide use similarity measure fall-back guessing rules.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	determined looking frequency number attributes unknown word.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	surprisingly, similarity system works better guessing rules information all.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	results summarised Table 6.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Table 7 shows breakdown performance supersense.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	columns show number instances supersense precision, recall f-score measures percentages.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	frequent supersenses test sets person, attribute act.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	factors conducive extracting reliable synonyms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	alternative approach worth exploring create context vectors supersense categories compare words.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	advantage producing much smaller number vectors compare against.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	question becomes construct vectors supersenses.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	obvious solution sum context vectors across words supersense.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Also, questions arise construction vectors.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	words multiple supersenses handled?	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, given sparseness data may leave large context vectors.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	number problems system currently handle.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Further, similarity system currently incorporate multi-word terms.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	overcome using synonyms last word multi-word term.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	consistency classifying similar words categories.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	supersenses synonyms combined determine supersense.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	names descriptions noun lex-files shown Table 1.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita et al.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	co-occurrence window 500 words designed approximate average document length.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	measure found successful entropy conditional distribution surrounding words given noun.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Specificity ordering necessary step building noun hierarchy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, approach clearly cannot build hierarchy alone.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	instance, entity less frequent many concepts subsumes.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	technique used approach supersense tagging.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	developed efficient algorithm estimating model hierarchical training data.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	examples test sets given Table 2 supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	components sizes including punctuation given Table 3.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	LDC recently released English Gigaword corpus includes corpora listed above.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	rest pipeline described next section.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	key parameters context extraction method similarity measure used compare context vectors.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	describe shallow pipeline detail below.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, morphological smoothing still produces better results practice.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	6.1 Part Speech Tagging Chunking.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	6.2 Morphological Analysis.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	morpha wide coverage – nearly 100% across passes.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	global list used determine word already attached.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	types grammatical relation extracted SEXTANT shown Table 4.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	corresponds assuming right-branching noun compounds.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Within NP NP PP heads remain unattached.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	corresponds assuming right-branching PP attachment.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	phrase NP head remains unattached.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Tense Determination rightmost verb VP considered head.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	VP initially categorised active.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	head verb form VP becomes attributive.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	noun heads either side VPs remain unattached.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	example, antigen subject represent.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	VP classed active phrase NP direct object (dobj) relation created.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	VP classed passive phrase NP subject (subj) relation created.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	following phrase PP indirect object (iobj) relation created.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, SEXTANT always attaches PP previous phrase.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	progressive verb appears determiner quantifier considered noun.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	supersense guessing rules given Table 5.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	none rules match, default supersense artifact assigned.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	experiments described consider range options parameters.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	fact, experiments quick run able exhaustively test many combinations parameters.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	experimented 200 voting extracted synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	several ways weight synonym’s contribution.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	simplest approach would give synonym weight.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Another approach use scores returned similarity system.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Alternatively, weights use ranking extracted synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	options considered below.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	final issue deal polysemy.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	experiments performed considering possible configurations parameters described above.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	initial weight could divided number supersenses share weight (SHARED).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	weight could also divided rank (RANK) penalise supersenses list.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	extracted synonyms filtered contributing vote supersense(s).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	next question many synonyms considered.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	top performing configurations used 50 synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, filter turned make little difference.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Finally, need decide use similarity measure fall-back guessing rules.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	determined looking frequency number attributes unknown word.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	surprisingly, similarity system works better guessing rules information all.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	results summarised Table 6.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Table 7 shows breakdown performance supersense.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	columns show number instances supersense precision, recall f-score measures percentages.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	frequent supersenses test sets person, attribute act.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	factors conducive extracting reliable synonyms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	alternative approach worth exploring create context vectors supersense categories compare words.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	advantage producing much smaller number vectors compare against.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	question becomes construct vectors supersenses.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	obvious solution sum context vectors across words supersense.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Also, questions arise construction vectors.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	words multiple supersenses handled?	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, given sparseness data may leave large context vectors.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	number problems system currently handle.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Further, similarity system currently incorporate multi-word terms.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	overcome using synonyms last word multi-word term.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	1
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Supersense Tagging Unknown Nouns using Semantic Similarity	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	consistency classifying similar words categories.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	paper describes unsupervised approach supersense tagging require annotated sentences.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	supersenses synonyms combined determine supersense.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	names descriptions noun lex-files shown Table 1.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita et al.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	co-occurrence window 500 words designed approximate average document length.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	measure found successful entropy conditional distribution surrounding words given noun.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Specificity ordering necessary step building noun hierarchy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, approach clearly cannot build hierarchy alone.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	instance, entity less frequent many concepts subsumes.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	technique used approach supersense tagging.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	developed efficient algorithm estimating model hierarchical training data.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	evaluation use exactly test sets Ciaramita Johnson (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	examples test sets given Table 2 supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	components sizes including punctuation given Table 3.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	LDC recently released English Gigaword corpus includes corpora listed above.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	rest pipeline described next section.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	vector-space models headword represented vector frequency counts recording contexts appears in.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	key parameters context extraction method similarity measure used compare context vectors.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	describe shallow pipeline detail below.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, morphological smoothing still produces better results practice.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	6.1 Part Speech Tagging Chunking.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	6.2 Morphological Analysis.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	morpha wide coverage – nearly 100% across passes.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	global list used determine word already attached.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	types grammatical relation extracted SEXTANT shown Table 4.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	corresponds assuming right-branching noun compounds.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Within NP NP PP heads remain unattached.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	corresponds assuming right-branching PP attachment.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	phrase NP head remains unattached.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Tense Determination rightmost verb VP considered head.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	VP initially categorised active.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	head verb form VP becomes attributive.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	noun heads either side VPs remain unattached.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	remaining three passes attach verb heads either subjects objects depending voice VP.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	example, antigen subject represent.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	VP classed active phrase NP direct object (dobj) relation created.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	VP classed passive phrase NP subject (subj) relation created.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	following phrase PP indirect object (iobj) relation created.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, SEXTANT always attaches PP previous phrase.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	progressive verb appears determiner quantifier considered noun.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	supersense guessing rules given Table 5.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	none rules match, default supersense artifact assigned.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	extracted synonym votes one supersenses appear WORDNET 1.6.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	experiments described consider range options parameters.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	fact, experiments quick run able exhaustively test many combinations parameters.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	experimented 200 voting extracted synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	several ways weight synonym’s contribution.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	simplest approach would give synonym weight.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Another approach use scores returned similarity system.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Alternatively, weights use ranking extracted synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	options considered below.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	final issue deal polysemy.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	experiments performed considering possible configurations parameters described above.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	initial weight could divided number supersenses share weight (SHARED).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	weight could also divided rank (RANK) penalise supersenses list.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	extracted synonyms filtered contributing vote supersense(s).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	next question many synonyms considered.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	top performing configurations used 50 synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, filter turned make little difference.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Finally, need decide use similarity measure fall-back guessing rules.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	determined looking frequency number attributes unknown word.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	surprisingly, similarity system works better guessing rules information all.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	results summarised Table 6.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Table 7 shows breakdown performance supersense.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	columns show number instances supersense precision, recall f-score measures percentages.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	frequent supersenses test sets person, attribute act.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	factors conducive extracting reliable synonyms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	alternative approach worth exploring create context vectors supersense categories compare words.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	advantage producing much smaller number vectors compare against.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	question becomes construct vectors supersenses.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	obvious solution sum context vectors across words supersense.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Also, questions arise construction vectors.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	words multiple supersenses handled?	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, given sparseness data may leave large context vectors.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	number problems system currently handle.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Further, similarity system currently incorporate multi-word terms.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	overcome using synonyms last word multi-word term.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	1
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	consistency classifying similar words categories.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	supersenses synonyms combined determine supersense.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	names descriptions noun lex-files shown Table 1.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita et al.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	co-occurrence window 500 words designed approximate average document length.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	measure found successful entropy conditional distribution surrounding words given noun.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Specificity ordering necessary step building noun hierarchy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, approach clearly cannot build hierarchy alone.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	instance, entity less frequent many concepts subsumes.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	technique used approach supersense tagging.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	developed efficient algorithm estimating model hierarchical training data.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	examples test sets given Table 2 supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	components sizes including punctuation given Table 3.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	LDC recently released English Gigaword corpus includes corpora listed above.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	rest pipeline described next section.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	key parameters context extraction method similarity measure used compare context vectors.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	describe shallow pipeline detail below.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, morphological smoothing still produces better results practice.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	6.1 Part Speech Tagging Chunking.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	6.2 Morphological Analysis.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	morpha wide coverage – nearly 100% across passes.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	global list used determine word already attached.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	types grammatical relation extracted SEXTANT shown Table 4.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	corresponds assuming right-branching noun compounds.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Within NP NP PP heads remain unattached.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	corresponds assuming right-branching PP attachment.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	phrase NP head remains unattached.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Tense Determination rightmost verb VP considered head.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	VP initially categorised active.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	head verb form VP becomes attributive.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	noun heads either side VPs remain unattached.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	example, antigen subject represent.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	VP classed active phrase NP direct object (dobj) relation created.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	VP classed passive phrase NP subject (subj) relation created.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	following phrase PP indirect object (iobj) relation created.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, SEXTANT always attaches PP previous phrase.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	progressive verb appears determiner quantifier considered noun.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	supersense guessing rules given Table 5.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	none rules match, default supersense artifact assigned.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	experiments described consider range options parameters.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	fact, experiments quick run able exhaustively test many combinations parameters.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	experimented 200 voting extracted synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	several ways weight synonym’s contribution.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	simplest approach would give synonym weight.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Another approach use scores returned similarity system.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Alternatively, weights use ranking extracted synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	options considered below.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	final issue deal polysemy.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	experiments performed considering possible configurations parameters described above.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	initial weight could divided number supersenses share weight (SHARED).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	weight could also divided rank (RANK) penalise supersenses list.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	extracted synonyms filtered contributing vote supersense(s).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	next question many synonyms considered.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	top performing configurations used 50 synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, filter turned make little difference.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Finally, need decide use similarity measure fall-back guessing rules.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	determined looking frequency number attributes unknown word.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	surprisingly, similarity system works better guessing rules information all.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	results summarised Table 6.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Table 7 shows breakdown performance supersense.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	columns show number instances supersense precision, recall f-score measures percentages.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	frequent supersenses test sets person, attribute act.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	factors conducive extracting reliable synonyms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	alternative approach worth exploring create context vectors supersense categories compare words.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	advantage producing much smaller number vectors compare against.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	question becomes construct vectors supersenses.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	obvious solution sum context vectors across words supersense.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Also, questions arise construction vectors.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	words multiple supersenses handled?	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, given sparseness data may leave large context vectors.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	number problems system currently handle.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Further, similarity system currently incorporate multi-word terms.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	overcome using synonyms last word multi-word term.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	consistency classifying similar words categories.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	supersenses synonyms combined determine supersense.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	names descriptions noun lex-files shown Table 1.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita et al.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	co-occurrence window 500 words designed approximate average document length.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	measure found successful entropy conditional distribution surrounding words given noun.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Specificity ordering necessary step building noun hierarchy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, approach clearly cannot build hierarchy alone.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	instance, entity less frequent many concepts subsumes.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	technique used approach supersense tagging.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	1
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	developed efficient algorithm estimating model hierarchical training data.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	examples test sets given Table 2 supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	components sizes including punctuation given Table 3.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	LDC recently released English Gigaword corpus includes corpora listed above.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	rest pipeline described next section.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	key parameters context extraction method similarity measure used compare context vectors.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	describe shallow pipeline detail below.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, morphological smoothing still produces better results practice.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	6.1 Part Speech Tagging Chunking.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	6.2 Morphological Analysis.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	morpha wide coverage – nearly 100% across passes.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	global list used determine word already attached.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	types grammatical relation extracted SEXTANT shown Table 4.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	corresponds assuming right-branching noun compounds.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Within NP NP PP heads remain unattached.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	corresponds assuming right-branching PP attachment.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	phrase NP head remains unattached.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Tense Determination rightmost verb VP considered head.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	VP initially categorised active.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	head verb form VP becomes attributive.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	noun heads either side VPs remain unattached.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	example, antigen subject represent.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	VP classed active phrase NP direct object (dobj) relation created.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	VP classed passive phrase NP subject (subj) relation created.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	following phrase PP indirect object (iobj) relation created.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, SEXTANT always attaches PP previous phrase.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	progressive verb appears determiner quantifier considered noun.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	supersense guessing rules given Table 5.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	none rules match, default supersense artifact assigned.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	experiments described consider range options parameters.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	fact, experiments quick run able exhaustively test many combinations parameters.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	experimented 200 voting extracted synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	several ways weight synonym’s contribution.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	simplest approach would give synonym weight.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Another approach use scores returned similarity system.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Alternatively, weights use ranking extracted synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	options considered below.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	final issue deal polysemy.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	experiments performed considering possible configurations parameters described above.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	initial weight could divided number supersenses share weight (SHARED).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	weight could also divided rank (RANK) penalise supersenses list.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	extracted synonyms filtered contributing vote supersense(s).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	next question many synonyms considered.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	top performing configurations used 50 synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, filter turned make little difference.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Finally, need decide use similarity measure fall-back guessing rules.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	determined looking frequency number attributes unknown word.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	surprisingly, similarity system works better guessing rules information all.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	results summarised Table 6.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Table 7 shows breakdown performance supersense.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	columns show number instances supersense precision, recall f-score measures percentages.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	frequent supersenses test sets person, attribute act.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	factors conducive extracting reliable synonyms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	alternative approach worth exploring create context vectors supersense categories compare words.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	advantage producing much smaller number vectors compare against.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	question becomes construct vectors supersenses.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	obvious solution sum context vectors across words supersense.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Also, questions arise construction vectors.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	words multiple supersenses handled?	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, given sparseness data may leave large context vectors.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	number problems system currently handle.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Further, similarity system currently incorporate multi-word terms.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	overcome using synonyms last word multi-word term.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Supersense Tagging Unknown Nouns using Semantic Similarity	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	consistency classifying similar words categories.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	paper describes unsupervised approach supersense tagging require annotated sentences.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	supersenses synonyms combined determine supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	names descriptions noun lex-files shown Table 1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita et al.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	co-occurrence window 500 words designed approximate average document length.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	measure found successful entropy conditional distribution surrounding words given noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Specificity ordering necessary step building noun hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, approach clearly cannot build hierarchy alone.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	instance, entity less frequent many concepts subsumes.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	technique used approach supersense tagging.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	1
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	developed efficient algorithm estimating model hierarchical training data.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	evaluation use exactly test sets Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	examples test sets given Table 2 supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	components sizes including punctuation given Table 3.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	LDC recently released English Gigaword corpus includes corpora listed above.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	rest pipeline described next section.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	vector-space models headword represented vector frequency counts recording contexts appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	key parameters context extraction method similarity measure used compare context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	describe shallow pipeline detail below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, morphological smoothing still produces better results practice.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	6.1 Part Speech Tagging Chunking.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	6.2 Morphological Analysis.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	morpha wide coverage – nearly 100% across passes.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	global list used determine word already attached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	types grammatical relation extracted SEXTANT shown Table 4.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	corresponds assuming right-branching noun compounds.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Within NP NP PP heads remain unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	corresponds assuming right-branching PP attachment.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	phrase NP head remains unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Tense Determination rightmost verb VP considered head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	VP initially categorised active.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	head verb form VP becomes attributive.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	noun heads either side VPs remain unattached.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	remaining three passes attach verb heads either subjects objects depending voice VP.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	example, antigen subject represent.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	VP classed active phrase NP direct object (dobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	VP classed passive phrase NP subject (subj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	following phrase PP indirect object (iobj) relation created.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, SEXTANT always attaches PP previous phrase.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	progressive verb appears determiner quantifier considered noun.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	supersense guessing rules given Table 5.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	none rules match, default supersense artifact assigned.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	extracted synonym votes one supersenses appear WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	experiments described consider range options parameters.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	fact, experiments quick run able exhaustively test many combinations parameters.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	experimented 200 voting extracted synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	several ways weight synonym’s contribution.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	simplest approach would give synonym weight.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Another approach use scores returned similarity system.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Alternatively, weights use ranking extracted synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	options considered below.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	final issue deal polysemy.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	experiments performed considering possible configurations parameters described above.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	initial weight could divided number supersenses share weight (SHARED).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	weight could also divided rank (RANK) penalise supersenses list.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	extracted synonyms filtered contributing vote supersense(s).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	next question many synonyms considered.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	top performing configurations used 50 synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, filter turned make little difference.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Finally, need decide use similarity measure fall-back guessing rules.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	determined looking frequency number attributes unknown word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	surprisingly, similarity system works better guessing rules information all.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	results summarised Table 6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Table 7 shows breakdown performance supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	columns show number instances supersense precision, recall f-score measures percentages.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	frequent supersenses test sets person, attribute act.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	factors conducive extracting reliable synonyms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	alternative approach worth exploring create context vectors supersense categories compare words.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	advantage producing much smaller number vectors compare against.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	question becomes construct vectors supersenses.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	obvious solution sum context vectors across words supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Also, questions arise construction vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	words multiple supersenses handled?	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, given sparseness data may leave large context vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	number problems system currently handle.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Further, similarity system currently incorporate multi-word terms.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	overcome using synonyms last word multi-word term.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	consistency classifying similar words categories.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	supersenses synonyms combined determine supersense.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	names descriptions noun lex-files shown Table 1.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita et al.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	co-occurrence window 500 words designed approximate average document length.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	measure found successful entropy conditional distribution surrounding words given noun.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Specificity ordering necessary step building noun hierarchy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, approach clearly cannot build hierarchy alone.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	instance, entity less frequent many concepts subsumes.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	technique used approach supersense tagging.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	developed efficient algorithm estimating model hierarchical training data.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	examples test sets given Table 2 supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	components sizes including punctuation given Table 3.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	LDC recently released English Gigaword corpus includes corpora listed above.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	rest pipeline described next section.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	1
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	key parameters context extraction method similarity measure used compare context vectors.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	describe shallow pipeline detail below.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, morphological smoothing still produces better results practice.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	6.1 Part Speech Tagging Chunking.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	6.2 Morphological Analysis.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	morpha wide coverage – nearly 100% across passes.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	global list used determine word already attached.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	types grammatical relation extracted SEXTANT shown Table 4.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	corresponds assuming right-branching noun compounds.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Within NP NP PP heads remain unattached.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	corresponds assuming right-branching PP attachment.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	phrase NP head remains unattached.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Tense Determination rightmost verb VP considered head.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	VP initially categorised active.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	head verb form VP becomes attributive.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	noun heads either side VPs remain unattached.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	example, antigen subject represent.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	VP classed active phrase NP direct object (dobj) relation created.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	VP classed passive phrase NP subject (subj) relation created.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	following phrase PP indirect object (iobj) relation created.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, SEXTANT always attaches PP previous phrase.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	progressive verb appears determiner quantifier considered noun.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	supersense guessing rules given Table 5.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	none rules match, default supersense artifact assigned.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	experiments described consider range options parameters.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	fact, experiments quick run able exhaustively test many combinations parameters.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	experimented 200 voting extracted synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	several ways weight synonym’s contribution.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	simplest approach would give synonym weight.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Another approach use scores returned similarity system.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Alternatively, weights use ranking extracted synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	options considered below.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	final issue deal polysemy.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	experiments performed considering possible configurations parameters described above.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	initial weight could divided number supersenses share weight (SHARED).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	weight could also divided rank (RANK) penalise supersenses list.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	extracted synonyms filtered contributing vote supersense(s).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	next question many synonyms considered.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	top performing configurations used 50 synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, filter turned make little difference.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Finally, need decide use similarity measure fall-back guessing rules.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	determined looking frequency number attributes unknown word.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	surprisingly, similarity system works better guessing rules information all.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	results summarised Table 6.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Table 7 shows breakdown performance supersense.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	columns show number instances supersense precision, recall f-score measures percentages.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	frequent supersenses test sets person, attribute act.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	factors conducive extracting reliable synonyms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	alternative approach worth exploring create context vectors supersense categories compare words.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	advantage producing much smaller number vectors compare against.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	question becomes construct vectors supersenses.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	obvious solution sum context vectors across words supersense.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Also, questions arise construction vectors.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	words multiple supersenses handled?	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, given sparseness data may leave large context vectors.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	number problems system currently handle.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Further, similarity system currently incorporate multi-word terms.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	overcome using synonyms last word multi-word term.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	consistency classifying similar words categories.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	supersenses synonyms combined determine supersense.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	names descriptions noun lex-files shown Table 1.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita et al.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	co-occurrence window 500 words designed approximate average document length.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	measure found successful entropy conditional distribution surrounding words given noun.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Specificity ordering necessary step building noun hierarchy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, approach clearly cannot build hierarchy alone.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	instance, entity less frequent many concepts subsumes.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	technique used approach supersense tagging.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	developed efficient algorithm estimating model hierarchical training data.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	examples test sets given Table 2 supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	components sizes including punctuation given Table 3.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	LDC recently released English Gigaword corpus includes corpora listed above.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	rest pipeline described next section.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	key parameters context extraction method similarity measure used compare context vectors.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	describe shallow pipeline detail below.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, morphological smoothing still produces better results practice.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	6.1 Part Speech Tagging Chunking.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	6.2 Morphological Analysis.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	morpha wide coverage – nearly 100% across passes.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	global list used determine word already attached.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	types grammatical relation extracted SEXTANT shown Table 4.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	corresponds assuming right-branching noun compounds.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Within NP NP PP heads remain unattached.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	corresponds assuming right-branching PP attachment.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	phrase NP head remains unattached.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Tense Determination rightmost verb VP considered head.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	VP initially categorised active.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	head verb form VP becomes attributive.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	noun heads either side VPs remain unattached.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	example, antigen subject represent.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	VP classed active phrase NP direct object (dobj) relation created.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	VP classed passive phrase NP subject (subj) relation created.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	following phrase PP indirect object (iobj) relation created.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, SEXTANT always attaches PP previous phrase.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	progressive verb appears determiner quantifier considered noun.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	supersense guessing rules given Table 5.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	none rules match, default supersense artifact assigned.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	experiments described consider range options parameters.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	fact, experiments quick run able exhaustively test many combinations parameters.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	experimented 200 voting extracted synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	several ways weight synonym’s contribution.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	simplest approach would give synonym weight.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Another approach use scores returned similarity system.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Alternatively, weights use ranking extracted synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	options considered below.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	final issue deal polysemy.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	experiments performed considering possible configurations parameters described above.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	initial weight could divided number supersenses share weight (SHARED).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	weight could also divided rank (RANK) penalise supersenses list.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	extracted synonyms filtered contributing vote supersense(s).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	next question many synonyms considered.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	top performing configurations used 50 synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, filter turned make little difference.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Finally, need decide use similarity measure fall-back guessing rules.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	determined looking frequency number attributes unknown word.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	surprisingly, similarity system works better guessing rules information all.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	results summarised Table 6.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Table 7 shows breakdown performance supersense.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	columns show number instances supersense precision, recall f-score measures percentages.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	frequent supersenses test sets person, attribute act.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	factors conducive extracting reliable synonyms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	alternative approach worth exploring create context vectors supersense categories compare words.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	advantage producing much smaller number vectors compare against.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	question becomes construct vectors supersenses.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	obvious solution sum context vectors across words supersense.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Also, questions arise construction vectors.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	words multiple supersenses handled?	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, given sparseness data may leave large context vectors.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	number problems system currently handle.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Further, similarity system currently incorporate multi-word terms.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	overcome using synonyms last word multi-word term.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	consistency classifying similar words categories.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	supersenses synonyms combined determine supersense.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	names descriptions noun lex-files shown Table 1.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita et al.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	co-occurrence window 500 words designed approximate average document length.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	measure found successful entropy conditional distribution surrounding words given noun.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Specificity ordering necessary step building noun hierarchy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, approach clearly cannot build hierarchy alone.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	instance, entity less frequent many concepts subsumes.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	technique used approach supersense tagging.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	1
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	developed efficient algorithm estimating model hierarchical training data.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	examples test sets given Table 2 supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	components sizes including punctuation given Table 3.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	LDC recently released English Gigaword corpus includes corpora listed above.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	rest pipeline described next section.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	key parameters context extraction method similarity measure used compare context vectors.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	describe shallow pipeline detail below.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, morphological smoothing still produces better results practice.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	6.1 Part Speech Tagging Chunking.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	6.2 Morphological Analysis.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	morpha wide coverage – nearly 100% across passes.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	global list used determine word already attached.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	types grammatical relation extracted SEXTANT shown Table 4.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	corresponds assuming right-branching noun compounds.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Within NP NP PP heads remain unattached.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	corresponds assuming right-branching PP attachment.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	phrase NP head remains unattached.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Tense Determination rightmost verb VP considered head.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	VP initially categorised active.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	head verb form VP becomes attributive.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	noun heads either side VPs remain unattached.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	example, antigen subject represent.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	VP classed active phrase NP direct object (dobj) relation created.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	VP classed passive phrase NP subject (subj) relation created.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	following phrase PP indirect object (iobj) relation created.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, SEXTANT always attaches PP previous phrase.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	progressive verb appears determiner quantifier considered noun.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	supersense guessing rules given Table 5.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	none rules match, default supersense artifact assigned.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	experiments described consider range options parameters.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	fact, experiments quick run able exhaustively test many combinations parameters.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	experimented 200 voting extracted synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	several ways weight synonym’s contribution.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	simplest approach would give synonym weight.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Another approach use scores returned similarity system.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Alternatively, weights use ranking extracted synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	options considered below.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	final issue deal polysemy.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	experiments performed considering possible configurations parameters described above.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	initial weight could divided number supersenses share weight (SHARED).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	weight could also divided rank (RANK) penalise supersenses list.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	extracted synonyms filtered contributing vote supersense(s).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	next question many synonyms considered.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	top performing configurations used 50 synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, filter turned make little difference.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Finally, need decide use similarity measure fall-back guessing rules.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	determined looking frequency number attributes unknown word.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	surprisingly, similarity system works better guessing rules information all.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	results summarised Table 6.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Table 7 shows breakdown performance supersense.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	columns show number instances supersense precision, recall f-score measures percentages.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	frequent supersenses test sets person, attribute act.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	factors conducive extracting reliable synonyms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	alternative approach worth exploring create context vectors supersense categories compare words.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	advantage producing much smaller number vectors compare against.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	question becomes construct vectors supersenses.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	obvious solution sum context vectors across words supersense.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Also, questions arise construction vectors.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	words multiple supersenses handled?	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, given sparseness data may leave large context vectors.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	number problems system currently handle.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Further, similarity system currently incorporate multi-word terms.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	overcome using synonyms last word multi-word term.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Supersense Tagging Unknown Nouns using Semantic Similarity	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	limited coverage lexical-semantic resources significant problem NLP systems alleviated automatically classifying unknown words.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Supersense tagging assigns unknown nouns one 26 broad semantic categories used lexicographers organise manual insertion WORDNET.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) present tagger uses synonym set glosses annotated training examples.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	describe unsupervised approach, based vector-space similarity, require annotated examples significantly outperforms tagger.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	also demonstrate use extremely large shallow-parsed corpus calculating vector-space semantic similarity.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Lexical-semantic resources applied successful wide range Natural Language Processing (NLP) problems ranging collocation extraction (Pearce, 2001) class-based smoothing (Clark Weir, 2002), text classification (Baker McCallum, 1998) question answering (Pasca Harabagiu, 2001).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	particular, WORDNET (Fellbaum, 1998) significantly influenced research NLP.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Unfortunately, resource extremely time- consuming labour-intensive manually develop maintain, requiring considerable linguistic domain expertise.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Lexicographers cannot possibly keep pace language evolution: sense distinctions continually made merged, words coined become obsolete, technical terms migrate vernacular.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Technical domains, medicine, require separate treatment since common words often take special meanings, significant proportion vocabulary overlap everyday vocabulary.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Bur- gun Bodenreider (2001) compared alignment WORDNET UMLS medical resource found small degree overlap.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Also, lexical- semantic resources suffer from: bias towards concepts senses particular topics.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	specialist topics better covered WORD- NET others, e.g. dog finer-grained distinctions cat worm although reflect finer distinctions reality; limited coverage infrequent words senses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) found common nouns missing WORDNET 1.6 occurred every 8 sentences BLLIP corpus.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	WORDNET 2.0, coverage improved problem keeping language evolution remains difficult.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	consistency classifying similar words categories.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	instance, WORDNET lexicographer file ionosphere (location) different exo- sphere stratosphere (object), two layers earth’s atmosphere.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	problems demonstrate need automatic semiautomatic methods creation maintenance lexical-semantic resources.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Broad semantic classification currently used lexicographers or- ganise manual insertion words WORDNET, experimental precursor automatically inserting words directly WORDNET hierarchy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) call supersense tagging describe multi-class perceptron tagger, uses WORDNET’s hierarchical structure create many annotated training instances synset glosses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	paper describes unsupervised approach supersense tagging require annotated sentences.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Instead, use vector-space similarity retrieve number synonyms unknown common noun.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	supersenses synonyms combined determine supersense.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	approach significantly outperforms multi-class perceptron dataset based WORDNET 1.6 1.7.1.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	26 Proceedings 43rd Annual Meeting ACL, pages 26–33, Ann Arbor, June 2005.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Qc 2005 Association Computational Linguistics L E X -FI L E E C R P N act acts actions animal animals artifact man-made objects attribute attributes people objects body body parts cognition cognitive processes contents communication communicative processes contents event natural events feeling feelings emotions food foods drinks group groupings people objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession transfer possession process natural processes quantity quantities units measure relation relations people/things/ideas shape two three dimensional shapes state stable states affairs substance substances time time temporal relations Table 1: 25 noun lexicographer files WORDNET	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	26 broad semantic classes employed lexicographers initial phase inserting words WORDNET hierarchy, called lexicographer files (lex- files).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	noun hierarchy, 25 lex-files file containing top level nodes hierarchy called Tops.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	syntactic classes also organised using lex-files: 15 verbs, 3 adjectives 1 adverbs.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Lex-files form set coarse-grained sense distinctions within WORDNET.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	example, company appears following lex-files WORDNET 2.0: group, covers company social, commercial troupe fine-grained senses; state, covers companionship.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	names descriptions noun lex-files shown Table 1.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	lex-files map directly top level nodes hierarchy, called unique beginners, others grouped together hyponyms unique beginner (Fellbaum, 1998, page 30).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	example, abstraction subsumes lex-files attribute, quantity, relation, communication time.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) call noun lex-file classes supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	11 unique beginners WORDNET noun hierarchy could also used supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita (2002) produced mini- WORDNET manually reducing WORDNET hierarchy 106 broad categories.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita et al.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	(2003) describe lex-files used root nodes two level hierarchy WORDNET synsets appear ing directly underneath.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	alternative sets supersenses created arbitrary cut WORDNET hierarchy near top, using topics thesaurus Roget’s (Yarowsky, 1992).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	topic distinctions coarser-grained WORDNET senses, criticised difficult distinguish even experts.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) believe key sense distinctions still maintained supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	suggest supersense tagging similar named entity recognition, also small set categories similar granularity (e.g. location person) labelling predominantly unseen terms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Supersense tagging provide automated semi- automated assistance lexicographers adding words WORDNET hierarchy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	task solved successfully, may possible insert words directly fine-grained distinctions hierarchy itself.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Clearly, ultimate goal, able insert new terms lexical resources, extending structure necessary.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Supersense tagging also interesting many applications use shallow semantics, e.g. information extraction question answering.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	considerable amount research addresses structurally statistically manipulating hierarchy WORD- NET construction new wordnets using concept structure English.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	lexical FreeNet, Beefer- man (1998) adds 350 000 collocation pairs (trigger pairs) extracted 160 million word corpus broadcast news using mutual information.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	co-occurrence window 500 words designed approximate average document length.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Caraballo Charniak (1999) explored determining noun specificity raw text.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	find simple frequency counts effective way determining parent-child ordering, achieving 83% accuracy types vehicle, food occupation.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	measure found successful entropy conditional distribution surrounding words given noun.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Specificity ordering necessary step building noun hierarchy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, approach clearly cannot build hierarchy alone.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	instance, entity less frequent many concepts subsumes.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	suggests possible add words existing abstract structure rather create categories right unique beginners.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Hearst Schu¨ tze (1993) flatten WORDNET 726 categories using algorithm attempts minimise variance category size.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	categories used label paragraphs topics, effectively repeating Yarowsky’s (1992) experiments using categories rather Roget’s thesaurus.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Schu¨ tze’s (1992) WordSpace system used add topical links, ball, racquet game (the tennis problem).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Further, also use vector-space techniques label previously unseen words using common class assigned top 20 synonyms word.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Widdows (2003) uses similar technique insert words WORDNET hierarchy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	first extracts synonyms unknown word using vector-space similarity measures based Latent Semantic Analysis searches location hierarchy nearest synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	technique used approach supersense tagging.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) implement super- sense tagger based multi-class perceptron classifier (Crammer Singer, 2001), uses standard collocation, spelling syntactic features common WSD named entity recognition systems.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	insight use WORDNET glosses annotated training data massively increase number training instances using noun hierarchy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	developed efficient algorithm estimating model hierarchical training data.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Ciaramita Johnson (2003) propose natural evaluation supersense tagging: inserting extra common nouns added new version WORDNET.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	use common nouns added WORDNET 1.7.1 since WORDNET 1.6 compare evaluation standard cross-validation approach uses small percentage words WORDNET 1.6 training set evaluation.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	results suggest WORDNET 1.7.1 test set significantly harder large number abstract category nouns, e.g. communication cognition, appear 1.7.1 data, difficult classify.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	evaluation use exactly test sets Ciaramita Johnson (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	WORDNET 1.7.1 test set consists 744 previously unseen nouns, majority (over 90%) one sense.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	WORD- NET 1.6 test set consists several cross-validation sets 755 nouns randomly selected BLLIP training set used Ciaramita Johnson (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	kindly supplied us WORDNET 1.7.1 test set one cross-validation run WORDNET 1.6 test set.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	development experiments performed WORDNET 1.6 test set one final run WORD- NET 1.7.1 test set.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	examples test sets given Table 2 supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	developed 2 billion word corpus, shallow- parsed statistical NLP pipeline, far Table 2: Example nouns supersenses largest NLP processed corpus described published search.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	corpus consists British National Corpus (BNC), Reuters Corpus Volume 1 (RCV1), Linguistic Data Consortium’s news text collected since 1987: Continuous Speech Recognition III (CSRIII); North American News Text Corpus (NANTC); NANTC Supplement (NANTS); ACQUAINT Corpus.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	components sizes including punctuation given Table 3.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	LDC recently released English Gigaword corpus includes corpora listed above.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	C R P U C . E N . WO R B N C 4 1 2 4 6 . 2 1 1 4 R C V1 8 0 6 7 9 1 8 . 1 2 0 7 C R -I 4 9 1 3 4 9 9 . 3 2 2 6 NA N C 9 3 0 3 6 7 2 3.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	2 5 5 9 NA N 9 4 2 1 6 7 2 5.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	2 5 0 7 AC QU N 1 03 3 46 1 2 1.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	3 4 9 1 Table 3: 2 billion word corpus statistics tokenized text using Grok OpenNLP tokenizer (Morton, 2002) split sentences using MXTerminator (Reynar Ratnaparkhi, 1997).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	sentences less 3 words 100 words long rejected, along sentences containing 5 numbers 4 brackets, reduce noise.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	rest pipeline described next section.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Similarity Vector-space models similarity based distributional hypothesis similar words appear similar contexts.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	hypothesis suggests semantic similarity measured comparing contexts word appears in.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	vector-space models headword represented vector frequency counts recording contexts appears in.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	key parameters context extraction method similarity measure used compare context vectors.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	approach vector-space similarity based SEXTANT system described Grefenstette (1994).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Curran Moens (2002b) compared several context extraction methods found shallow pipeline grammatical relation extraction used SEXTANT extremely fast produced high-quality results.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	SEXTANT extracts relation tuples (w, r, wt ) noun, w headword, r relation type wt word.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	efficiency SEXTANT approach makes extraction contextual information 2 billion words raw text feasible.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	describe shallow pipeline detail below.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Curran Moens (2002a) compared several different similarity measures found Grefenstette’s weighted JACCARD measure performed best: R E L N E C R P N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations SEXTANT CELEX lexical database (Minnen et al., 2001) – efficient, analysing 80 000 words per second.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	morpha often maintains sense distinctions singular plural nouns; instance: spectacles reduced spectacle, fails cases: glasses converted glass.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency problematic using morphological analysis smooth vector-space models.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, morphological smoothing still produces better results practice.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	wgt(w, r, wt ) weight function relation (w, r, wt ).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Curran Moens (2002a) introduced TTEST weight function, used collocation extraction.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Here, t-test compares joint product probability distributions headword context: 6.3 Grammatical Relation Extraction.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	raw text POS tagged chunked, grammatical relation extraction algorithm run chunks.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	consists five passes sentence first identify noun verb phrase heads p(w, r, wt ) − p(∗, r, wt )p(w, ∗, ∗) p(∗, r, wt )p(w, ∗, ∗) (2) collect grammatical relations common noun modifiers verbs.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	global list grammatical relations generated pass maintained ∗ indicates global sum element relation tuple.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	JACCARD TTEST produced better quality synonyms existing measures literature, use Curran Moen’s configuration super- sense tagging experiments.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	6.1 Part Speech Tagging Chunking.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	implementation SEXTANT uses maximum entropy POS tagger designed efficient, tagging around 100 000 words per second (Curran Clark, 2003), trained entire Penn Treebank (Marcus et al., 1994).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	similar performing tool Trigrams ‘n’ Tags tagger (Brants, 2000) uses much simpler statistical model.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	implementation uses maximum entropy chunker similar feature types Koeling (2000) also trained chunks extracted entire Penn Treebank using CoNLL 2000 script.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Since Penn Treebank separates PPs conjunctions NPs, concatenated match Grefenstette’s table-based results, i.e. SEXTANT always prefers noun attachment.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	6.2 Morphological Analysis.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	implementation uses morpha, Sussex morphological analyser (Minnen et al., 2001), implemented using lex grammars affix splitting generation.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	morpha wide coverage – nearly 100% across passes.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	global list used determine word already attached.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	five passes completed association list contains noun- modifier/verb pairs extracted sentence.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	types grammatical relation extracted SEXTANT shown Table 4.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	relations nouns (nn nnprep), also create inverse relations (wt , rt , w) representing fact wt modify w. 5 passes described below.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Pass 1: Noun Pre-modifiers pass scans NPs, left right, creating adjectival (adj) nominal (nn) pre-modifier grammatical relations (GRs) every noun pre-modifier’s right, preposition phrase end.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	corresponds assuming right-branching noun compounds.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Within NP NP PP heads remain unattached.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Pass 2: Noun Post-modifiers pass scans NPs, right left, creating post-modifier GRs unattached heads NPs PPs.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	preposition encountered noun heads, prepositional noun (nnprep) GR created, otherwise appositional noun (nn) GR created.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	corresponds assuming right-branching PP attachment.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	phrase NP head remains unattached.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Tense Determination rightmost verb VP considered head.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	VP initially categorised active.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	head verb form VP becomes attributive.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Otherwise, algorithm scans VP right left: auxiliary verb form encountered VP becomes passive; progressive verb (except being) encountered VP becomes active.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	noun heads either side VPs remain unattached.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	remaining three passes attach verb heads either subjects objects depending voice VP.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Pass 3: Verb Pre-Attachment pass scans sentences, right left, associating first NP head left VP head.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	VP active, subject (subj) relation created; otherwise, direct object (dobj) relation created.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	example, antigen subject represent.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Pass 4: Verb Post-Attachment pass scans sentences, left right, associating first NP PP head right VP head.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	VP classed active phrase NP direct object (dobj) relation created.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	VP classed passive phrase NP subject (subj) relation created.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	following phrase PP indirect object (iobj) relation created.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	interaction head verb preposition determine whether noun indirect object ditransitive verb alternatively head PP modifying verb.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, SEXTANT always attaches PP previous phrase.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Pass 5: Verb Progressive Participles final step process attach progressive verbs subjects objects (without concern whether already attached).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Progressive verbs function nouns, verbs adjectives na¨ıve approximation correct attachment made.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	progressive verb appears determiner quantifier considered noun.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Otherwise, verb passes 3 4 repeated attach subjects objects.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Finally, SEXTANT collapses nn, nnprep adj relations together single broad noun-modifier grammatical relation.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Grefenstette (1994) claims extractor grammatical relation accuracy 75% manu ally checking 60 sentences.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	approach uses voting across known supersenses automatically extracted synonyms, select super- sense unknown nouns.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	technique similar Hearst Schu¨ tze (1993) Widdows (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, sometimes unknown noun appear 2 billion word corpus, least appear frequently enough provide sufficient contextual information extract reliable synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	cases, SUFFIX EXAMPLE SUPERSENSEness remoteness attribute -tion, -ment annulment act -ist, -man statesman person -ing, -ion bowling act -ity viscosity attribute -ics, -ism electronics cognition -ene, -ane, -ine arsine substance -er, -or, -ic, -ee, -an mariner person -gy entomology cognition Table 5: Hand-coded rules supersense guessing fall-back method simple hand-coded classifier examines unknown noun makes guess based simple morphological analysis suffix.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	rules created inspecting suffixes rare nouns WORDNET 1.6.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	supersense guessing rules given Table 5.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	none rules match, default supersense artifact assigned.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	problem becomes convert ranked list extracted synonyms unknown noun single supersense selection.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	extracted synonym votes one supersenses appear WORDNET 1.6.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	many parameters consider: • many extracted synonyms use; • weight synonym’s vote; • whether unreliable synonyms filtered out; • deal polysemous synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	experiments described consider range options parameters.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	fact, experiments quick run able exhaustively test many combinations parameters.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	experimented 200 voting extracted synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	several ways weight synonym’s contribution.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	simplest approach would give synonym weight.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Another approach use scores returned similarity system.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Alternatively, weights use ranking extracted synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	options considered below.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	related question whether use extracted synonyms, perhaps filter synonyms small amount contextual information extracted, might unreliable.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	final issue deal polysemy.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	every supersense extracted synonym get whole weight synonym distributed evenly supersenses like Resnik (1995)?	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Another alternative consider unambiguous synonyms single supersense WORDNET.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	disadvantage similarity approach requires full synonym extraction, compares unknown word large number words when, E W N 1.6 W N 1.7 .1 Cia ra mit Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit bas ed res ult 6 8 % 6 3 % Table 6: Summary supersense tagging accuracies fact, want calculate similarity small number supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	inefficiency could reduced significantly consider high frequency words, even still expensive.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	used WORDNET 1.6 test set experiment different parameter settings kept WORDNET 1.7.1 test set final comparison best results Ciaramita Johnson (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	experiments performed considering possible configurations parameters described above.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	following voting options considered supersense extracted synonym: initial voting weight supersense could either constant (IDENTITY) similarity score (SCORE) synonym.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	initial weight could divided number supersenses share weight (SHARED).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	weight could also divided rank (RANK) penalise supersenses list.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	best performance 1.6 test set achieved SCORE voting, without sharing ranking penalties.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	extracted synonyms filtered contributing vote supersense(s).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	filtering involves checking synonym’s frequency number contexts large enough ensure reliable.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	experimented wide range cutoffs best performance 1.6 test set achieved using minimum cutoff 5 synonym’s frequency number contexts appears in.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	next question many synonyms considered.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	considered using nearest unambiguous synonym, top 5, 10, 20, 50, 100 200 synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	top performing configurations used 50 synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	also experimented filtering highly polysemous nouns eliminating words two, three synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, filter turned make little difference.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Finally, need decide use similarity measure fall-back guessing rules.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	determined looking frequency number attributes unknown word.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	surprisingly, similarity system works better guessing rules information all.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	results summarised Table 6.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	accuracy best-performing configurations 68% Table 7: Breakdown results supersense WORDNET 1.6 test set several parameter combinations described performing nearly well.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	previously unused WORDNET 1.7.1 test set, accuracy 63% using best system WORDNET 1.6 test set.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	optimising parameters 1.7.1 test set increase 64%, indicating excessively over-tuned 1.6 test set.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	results significantly outperform Ciaramita Johnson (2003) test sets even though system unsupervised.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	large difference 1.6 1.7.1 test set accuracy demonstrates 1.7.1 set much harder.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Table 7 shows breakdown performance supersense.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	columns show number instances supersense precision, recall f-score measures percentages.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	frequent supersenses test sets person, attribute act.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	frequent categories, person easiest supersense get correct 1.6 1.7.1 test sets, followed food, artifact substance.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	surprising since concrete words tend fewer senses, well constrained contexts relatively high frequency.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	factors conducive extracting reliable synonyms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	results also support Ciaramita Johnson’s view abstract concepts like communication, cognition state much harder.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	would expect location supersense perform well since quite concrete, unfortunately synonym extraction system incorporate proper nouns, many words classified using hand-built classifier.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Also, data Ciaramita Johnson words lower case, sensible guessing rules could help.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	alternative approach worth exploring create context vectors supersense categories compare words.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	advantage producing much smaller number vectors compare against.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	current system, must compare word entire vocabulary (over 500 000 headwords), much less efficient comparison 26 supersense context vectors.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	question becomes construct vectors supersenses.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	obvious solution sum context vectors across words supersense.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, early experiments suggest produces extremely large vectors match well much smaller vectors unseen word.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Also, questions arise construction vectors.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	words multiple supersenses handled?	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	preliminary experiments suggest combining vectors unambiguous words produces best results.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	One solution would take intersection vectors across words supersense (i.e. find common contexts words appear in).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, given sparseness data may leave large context vectors.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	final solution would consider large set canonical attributes (Curran Moens, 2002a) represent supersense.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Canonical attributes summarise key contexts headword used improve efficiency similarity comparisons.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	number problems system currently handle.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Firstly, include proper names similarity system means location entities difficult identify correctly (as results demonstrate).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Further, similarity system currently incorporate multi-word terms.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	overcome using synonyms last word multi-word term.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	However, 174 multi-word terms (23%) WORDNET 1.7.1 test set could probably tag accurately synonyms whole multi-word term.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Finally, plan implement supervised machine learner replace fall- back method, currently accuracy 37% WORDNET 1.7.1 test set.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	intend extend experiments beyond Ciaramita Johnson (2003) set include previous recent versions WORDNET compare difficulty, also perform experiments range corpus sizes determine impact corpus size quality results.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	would like move onto difficult task insertion hierarchy compare initial work Widdows (2003) using latent semantic analysis.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	issue combine vectors even interesting since additional structure WORDNET inheritance hierarchy small synonym sets used fine-grained combination vectors.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	application semantic similarity supersense tagging follows earlier work Hearst Schu¨ tze (1993) Widdows (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	classify previously unseen common noun approach extracts synonyms vote using supersenses WORDNET 1.6.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	experimented several parameters finding best configuration uses 50 extracted synonyms, filtered frequency number contexts increase reliability.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	synonym votes supersenses WORDNET 1.6 using similarity score synonym extractor.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	Using approach significantly outperformed supervised multi-class perceptron Ciaramita Johnson (2003).	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	paper also demonstrates use efficient shallow NLP pipeline process massive corpus.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	corpus needed acquire reliable contextual information often rare nouns attempting supersense tag.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	application semantic similarity demonstrates unsupervised methods outperform supervised methods NLP tasks enough data available.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	would like thank Massi Ciaramita supplying original data experiments answering queries, Stephen Clark anonymous reviewers helpful feedback corrections.	0
Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.	work supported Commonwealth scholarship, Sydney University Travelling Scholarship Australian Research Council Discovery Project DP0453131.	0
