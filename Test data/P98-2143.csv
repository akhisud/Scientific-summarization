Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Robust pronoun resolution limited knowledge	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Input checked agreement number antecedent indicators.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	immediate reference identified, priority given candi date best collocation pattern score.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	help, candidate higher score indicating verbs preferred.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	2.1 Antecedent indicators.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	following shall outline indicators used shall illustrate ex­ amples.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	new information, rheme, provides information theme.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	preference explained terms sali­ ence point view centering theory.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Example: Press keyi turn volume up...	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Press iti again.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	preference viewed modification collocation preference.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	also quite fre­ quent imperative constructions.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Example: print paper, stand printeri lay iti flat.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	turn printer, press Power buttoni hold iti moment.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Unwrap paperi• form iti align iti• load iti drawer.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	21dentification clauses complex sentences e heuristically.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	scores determined experimentally empirical basis constantly up­ dated.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	point antecedent indicators preferences absolute factors.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	2.2 Informal description algorithm.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Examine current sentence two pre­.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	ceding sentences (if available).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Look noun phrases3 left anaphor4 2.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Select noun phrases identified only.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	agree gender numberS pronominal anaphor group set potential candidates	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	antecedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	immediate reference hold, propose candidate higher score collocational pattern.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	indicator hold again, go recent candidate.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	3.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Evaluation.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evaluation, however, suggests much less lost might feared.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	resolution anaphors carried suc­ cess rate 95.8%.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Example: Identify draweq lit paper port LED add paper itj.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evaluation indicated 83.6% success rate.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evaluation estab­ lished critical success rate 82%.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	7 % 31.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	expected, frequent indica­ tors discriminative ones.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	3.3 Comparison similar approaches: compara­.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	CogNIAC successfully resolved pronouns 75% cases.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	result comparable results described (Baldwin 1997).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	"languages attractive feature NLP approach would language ""universality""."	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	time being, using scores Polish.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	preference-based approach showed clear su­ periority baseline models.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Nevertheless, recent results show that knowledge-poor methods perform with amazing acÂ­ curacy (cf.  (Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	2.1 Antecedent indicators.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	new information, rheme, provides information theme.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Example: Press keyi turn volume up...	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Press iti again.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	preference viewed modification collocation preference.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	2.2 Informal description algorithm.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Examine current sentence two pre­.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	ceding sentences (if available).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Select noun phrases identified only.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	antecedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	indicator hold again, go recent candidate.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	3.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Evaluation.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	7 % 31.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	time being, using scores Polish.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The anaphora resolver is an adaptation for Bulgarian of Mitkovs knowledge-poor pronoun resolution approach (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Robust pronoun resolution limited knowledge	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Input checked agreement number antecedent indicators.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	immediate reference identified, priority given candi date best collocation pattern score.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	help, candidate higher score indicating verbs preferred.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	still choice possible, recent remaining candi­ dates selected antecedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	2.1 Antecedent indicators.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	following shall outline indicators used shall illustrate ex­ amples.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	new information, rheme, provides information theme.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	preference explained terms sali­ ence point view centering theory.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Example: Press keyi turn volume up...	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Press iti again.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	preference viewed modification collocation preference.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	also quite fre­ quent imperative constructions.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Example: print paper, stand printeri lay iti flat.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	turn printer, press Power buttoni hold iti moment.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Unwrap paperi• form iti align iti• load iti drawer.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	21dentification clauses complex sentences e heuristically.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	scores determined experimentally empirical basis constantly up­ dated.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	point antecedent indicators preferences absolute factors.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"might cases one antecedent indicators ""point"" correct antecedent."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	2.2 Informal description algorithm.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Examine current sentence two pre­.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	ceding sentences (if available).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Look noun phrases3 left anaphor4 2.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Select noun phrases identified only.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	agree gender numberS pronominal anaphor group set potential candidates	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	antecedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	immediate reference hold, propose candidate higher score collocational pattern.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	indicator hold again, go recent candidate.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	3.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Evaluation.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evaluation, however, suggests much less lost might feared.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	resolution anaphors carried suc­ cess rate 95.8%.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Example: Identify draweq lit paper port LED add paper itj.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evaluation indicated 83.6% success rate.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evaluation estab­ lished critical success rate 82%.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	7 % 31.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	expected, frequent indica­ tors discriminative ones.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	3.3 Comparison similar approaches: compara­.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	CogNIAC successfully resolved pronouns 75% cases.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	result comparable results described (Baldwin 1997).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	"languages attractive feature NLP approach would language ""universality""."	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	time being, using scores Polish.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	preference-based approach showed clear su­ periority baseline models.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
This module resolves third-person personal pronouns and is an adaptation of Mitkovâ€™s robust, knowledge-poor multilingual approach (Mitkov, 1998) whose latest implementation by R. Evans is referred to as MARS 2 (Orasan et al., 2000).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	2.1 Antecedent indicators.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	new information, rheme, provides information theme.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Example: Press keyi turn volume up...	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Press iti again.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	preference viewed modification collocation preference.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	2.2 Informal description algorithm.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Examine current sentence two pre­.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	ceding sentences (if available).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Select noun phrases identified only.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	antecedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	indicator hold again, go recent candidate.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	3.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Evaluation.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	7 % 31.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	time being, using scores Polish.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
LINGUA performs the pre-processing, needed as an input to the anaphora resolution algorithm: sentence, paragraph and clause splitters, NP grammar, part-of-speech tagger, 2 MARS stands for Mitkovâ€™s Anaphora Resolution.  System.  3 For a detailed procedure how candidates are handled in the event of a tie, see (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Robust pronoun resolution limited knowledge	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Input checked agreement number antecedent indicators.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	immediate reference identified, priority given candi date best collocation pattern score.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	help, candidate higher score indicating verbs preferred.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	2.1 Antecedent indicators.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	following shall outline indicators used shall illustrate ex­ amples.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	new information, rheme, provides information theme.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	preference explained terms sali­ ence point view centering theory.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Example: Press keyi turn volume up...	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Press iti again.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	preference viewed modification collocation preference.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	also quite fre­ quent imperative constructions.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Example: print paper, stand printeri lay iti flat.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	turn printer, press Power buttoni hold iti moment.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Unwrap paperi• form iti align iti• load iti drawer.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	21dentification clauses complex sentences e heuristically.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	scores determined experimentally empirical basis constantly up­ dated.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	point antecedent indicators preferences absolute factors.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	2.2 Informal description algorithm.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Examine current sentence two pre­.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	ceding sentences (if available).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Look noun phrases3 left anaphor4 2.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Select noun phrases identified only.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	agree gender numberS pronominal anaphor group set potential candidates	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	antecedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	immediate reference hold, propose candidate higher score collocational pattern.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	indicator hold again, go recent candidate.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	3.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Evaluation.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evaluation, however, suggests much less lost might feared.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	resolution anaphors carried suc­ cess rate 95.8%.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Example: Identify draweq lit paper port LED add paper itj.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evaluation indicated 83.6% success rate.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evaluation estab­ lished critical success rate 82%.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	7 % 31.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	expected, frequent indica­ tors discriminative ones.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	3.3 Comparison similar approaches: compara­.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	CogNIAC successfully resolved pronouns 75% cases.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	result comparable results described (Baldwin 1997).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	"languages attractive feature NLP approach would language ""universality""."	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	time being, using scores Polish.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	preference-based approach showed clear su­ periority baseline models.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Most of the indicators have been adopted in LINGUA without modification from the original English version (see (Mitkov, 1998) for more details).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Robust pronoun resolution limited knowledge	1
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Input checked agreement number antecedent indicators.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	immediate reference identified, priority given candi date best collocation pattern score.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	help, candidate higher score indicating verbs preferred.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	2.1 Antecedent indicators.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	following shall outline indicators used shall illustrate ex­ amples.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	new information, rheme, provides information theme.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	preference explained terms sali­ ence point view centering theory.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Example: Press keyi turn volume up...	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Press iti again.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	preference viewed modification collocation preference.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	also quite fre­ quent imperative constructions.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Example: print paper, stand printeri lay iti flat.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	turn printer, press Power buttoni hold iti moment.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Unwrap paperi• form iti align iti• load iti drawer.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	21dentification clauses complex sentences e heuristically.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	scores determined experimentally empirical basis constantly up­ dated.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	point antecedent indicators preferences absolute factors.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	2.2 Informal description algorithm.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Examine current sentence two pre­.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	ceding sentences (if available).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Look noun phrases3 left anaphor4 2.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Select noun phrases identified only.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	agree gender numberS pronominal anaphor group set potential candidates	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	antecedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	immediate reference hold, propose candidate higher score collocational pattern.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	indicator hold again, go recent candidate.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	3.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Evaluation.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evaluation, however, suggests much less lost might feared.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	resolution anaphors carried suc­ cess rate 95.8%.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Example: Identify draweq lit paper port LED add paper itj.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evaluation indicated 83.6% success rate.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evaluation estab­ lished critical success rate 82%.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	7 % 31.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	expected, frequent indica­ tors discriminative ones.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	3.3 Comparison similar approaches: compara­.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	CogNIAC successfully resolved pronouns 75% cases.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	result comparable results described (Baldwin 1997).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	"languages attractive feature NLP approach would language ""universality""."	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	time being, using scores Polish.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	preference-based approach showed clear su­ periority baseline models.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	2.1 Antecedent indicators.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	new information, rheme, provides information theme.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Example: Press keyi turn volume up...	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Press iti again.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	preference viewed modification collocation preference.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	2.2 Informal description algorithm.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Examine current sentence two pre­.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	ceding sentences (if available).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Select noun phrases identified only.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	antecedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	indicator hold again, go recent candidate.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	3.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Evaluation.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	7 % 31.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	time being, using scores Polish.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Binding constraints have been in the focus of linguistic research for more than thirty years.  They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e. parsers (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Robust pronoun resolution limited knowledge	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Input checked agreement number antecedent indicators.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Candidates assigned scores indicator candidate highest score returned antecedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	immediate reference identified, priority given candi date best collocation pattern score.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	help, candidate higher score indicating verbs preferred.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	still choice possible, recent remaining candi­ dates selected antecedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	2.1 Antecedent indicators.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	following shall outline indicators used shall illustrate ex­ amples.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	new information, rheme, provides information theme.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Example: Insert cassettei VCR making sure iti suitable length recording.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	preference explained terms sali­ ence point view centering theory.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Example: Press keyi turn volume up...	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Press iti again.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	preference viewed modification collocation preference.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	also quite fre­ quent imperative constructions.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Example: print paper, stand printeri lay iti flat.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	turn printer, press Power buttoni hold iti moment.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Unwrap paperi• form iti align iti• load iti drawer.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	21dentification clauses complex sentences e heuristically.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	scores determined experimentally empirical basis constantly up­ dated.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	point antecedent indicators preferences absolute factors.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"might cases one antecedent indicators ""point"" correct antecedent."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	2.2 Informal description algorithm.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	algorithm pronoun resolution de­ scribed informally follows: 1.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Examine current sentence two pre­.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	ceding sentences (if available).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Look noun phrases3 left anaphor4 2.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Select noun phrases identified only.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	agree gender numberS pronominal anaphor group set potential candidates	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	antecedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	immediate reference hold, propose candidate higher score collocational pattern.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	indicator hold again, go recent candidate.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	3.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Evaluation.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evaluation, however, suggests much less lost might feared.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	resolution anaphors carried suc­ cess rate 95.8%.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Example: Identify draweq lit paper port LED add paper itj.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evaluation indicated 83.6% success rate.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evaluation estab­ lished critical success rate 82%.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	7 % 31.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	expected, frequent indica­ tors discriminative ones.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	3.3 Comparison similar approaches: compara­.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	CogNIAC successfully resolved pronouns 75% cases.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	result comparable results described (Baldwin 1997).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	"languages attractive feature NLP approach would language ""universality""."	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	time being, using scores Polish.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	preference-based approach showed clear su­ periority baseline models.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
However, the pressing need for the development of robust and inexpensive solutions encouraged the drive toward knowledge-poor strategies (Dagan and Itai 1990; Lappin and Leass 1994; Mitkov 1998;	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Robust pronoun resolution limited knowledge	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Input checked agreement number antecedent indicators.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	immediate reference identified, priority given candi date best collocation pattern score.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	help, candidate higher score indicating verbs preferred.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	still choice possible, recent remaining candi­ dates selected antecedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	2.1 Antecedent indicators.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	following shall outline indicators used shall illustrate ex­ amples.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	new information, rheme, provides information theme.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	preference explained terms sali­ ence point view centering theory.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Example: Press keyi turn volume up...	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Press iti again.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	preference viewed modification collocation preference.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	also quite fre­ quent imperative constructions.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Example: print paper, stand printeri lay iti flat.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	turn printer, press Power buttoni hold iti moment.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Unwrap paperi• form iti align iti• load iti drawer.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	1
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	21dentification clauses complex sentences e heuristically.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	scores determined experimentally empirical basis constantly up­ dated.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	point antecedent indicators preferences absolute factors.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"might cases one antecedent indicators ""point"" correct antecedent."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	2.2 Informal description algorithm.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Examine current sentence two pre­.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	ceding sentences (if available).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Look noun phrases3 left anaphor4 2.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Select noun phrases identified only.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	agree gender numberS pronominal anaphor group set potential candidates	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	antecedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	immediate reference hold, propose candidate higher score collocational pattern.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	indicator hold again, go recent candidate.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	3.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Evaluation.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evaluation, however, suggests much less lost might feared.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	resolution anaphors carried suc­ cess rate 95.8%.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Example: Identify draweq lit paper port LED add paper itj.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evaluation indicated 83.6% success rate.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evaluation estab­ lished critical success rate 82%.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	7 % 31.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	expected, frequent indica­ tors discriminative ones.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	3.3 Comparison similar approaches: compara­.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	CogNIAC successfully resolved pronouns 75% cases.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	result comparable results described (Baldwin 1997).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	"languages attractive feature NLP approach would language ""universality""."	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	time being, using scores Polish.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	preference-based approach showed clear su­ periority baseline models.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The search scope for candidate antecedents is set to the current sentence together with the three preceding sentences as suggested in (Mitkov, 1998)	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Robust pronoun resolution limited knowledge	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Input checked agreement number antecedent indicators.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	immediate reference identified, priority given candi date best collocation pattern score.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	help, candidate higher score indicating verbs preferred.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	2.1 Antecedent indicators.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	following shall outline indicators used shall illustrate ex­ amples.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	new information, rheme, provides information theme.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	preference explained terms sali­ ence point view centering theory.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Example: Press keyi turn volume up...	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Press iti again.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	preference viewed modification collocation preference.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	also quite fre­ quent imperative constructions.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Example: print paper, stand printeri lay iti flat.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	turn printer, press Power buttoni hold iti moment.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Unwrap paperi• form iti align iti• load iti drawer.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	21dentification clauses complex sentences e heuristically.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	scores determined experimentally empirical basis constantly up­ dated.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	point antecedent indicators preferences absolute factors.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	2.2 Informal description algorithm.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Examine current sentence two pre­.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	ceding sentences (if available).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Look noun phrases3 left anaphor4 2.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Select noun phrases identified only.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	agree gender numberS pronominal anaphor group set potential candidates	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	antecedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	immediate reference hold, propose candidate higher score collocational pattern.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	indicator hold again, go recent candidate.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	3.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Evaluation.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evaluation, however, suggests much less lost might feared.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	resolution anaphors carried suc­ cess rate 95.8%.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Example: Identify draweq lit paper port LED add paper itj.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evaluation indicated 83.6% success rate.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evaluation estab­ lished critical success rate 82%.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	7 % 31.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	expected, frequent indica­ tors discriminative ones.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	3.3 Comparison similar approaches: compara­.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	CogNIAC successfully resolved pronouns 75% cases.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	result comparable results described (Baldwin 1997).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	"languages attractive feature NLP approach would language ""universality""."	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	time being, using scores Polish.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	preference-based approach showed clear su­ periority baseline models.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Like many heuristic-based pronoun resolvers (e.g., Mitkov (1998)), they first apply a set of constraints to filter grammatically incompatible candidate antecedents and then rank the remaining ones using salience factors.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Robust pronoun resolution limited knowledge	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Input checked agreement number antecedent indicators.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	help, candidate higher score indicating verbs preferred.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	2.1 Antecedent indicators.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	new information, rheme, provides information theme.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	preference explained terms sali­ ence point view centering theory.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Example: Press keyi turn volume up...	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Press iti again.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	preference viewed modification collocation preference.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	also quite fre­ quent imperative constructions.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Example: print paper, stand printeri lay iti flat.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	turn printer, press Power buttoni hold iti moment.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	21dentification clauses complex sentences e heuristically.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	point antecedent indicators preferences absolute factors.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	2.2 Informal description algorithm.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Examine current sentence two pre­.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	ceding sentences (if available).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Look noun phrases3 left anaphor4 2.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Select noun phrases identified only.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	antecedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	indicator hold again, go recent candidate.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	3.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Evaluation.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evaluation, however, suggests much less lost might feared.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evaluation indicated 83.6% success rate.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evaluation estab­ lished critical success rate 82%.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	7 % 31.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	expected, frequent indica­ tors discriminative ones.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	3.3 Comparison similar approaches: compara­.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	result comparable results described (Baldwin 1997).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	"languages attractive feature NLP approach would language ""universality""."	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	time being, using scores Polish.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	preference-based approach showed clear su­ periority baseline models.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
A huge variety of techniques are described in the literature, many of them achieving high sucÂ­ cess rates on their own evaluation texts (cf.  Hobbs 1986; Strube 1998; Mitkov 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Robust pronoun resolution limited knowledge	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Input checked agreement number antecedent indicators.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	immediate reference identified, priority given candi date best collocation pattern score.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	help, candidate higher score indicating verbs preferred.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	2.1 Antecedent indicators.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	following shall outline indicators used shall illustrate ex­ amples.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	new information, rheme, provides information theme.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	preference explained terms sali­ ence point view centering theory.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Example: Press keyi turn volume up...	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Press iti again.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	preference viewed modification collocation preference.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	also quite fre­ quent imperative constructions.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Example: print paper, stand printeri lay iti flat.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	turn printer, press Power buttoni hold iti moment.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Unwrap paperi• form iti align iti• load iti drawer.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	21dentification clauses complex sentences e heuristically.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	scores determined experimentally empirical basis constantly up­ dated.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	point antecedent indicators preferences absolute factors.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	2.2 Informal description algorithm.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Examine current sentence two pre­.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	ceding sentences (if available).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Look noun phrases3 left anaphor4 2.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Select noun phrases identified only.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	agree gender numberS pronominal anaphor group set potential candidates	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	antecedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	immediate reference hold, propose candidate higher score collocational pattern.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	indicator hold again, go recent candidate.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	3.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Evaluation.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evaluation, however, suggests much less lost might feared.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	resolution anaphors carried suc­ cess rate 95.8%.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Example: Identify draweq lit paper port LED add paper itj.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evaluation indicated 83.6% success rate.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evaluation estab­ lished critical success rate 82%.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	7 % 31.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	expected, frequent indica­ tors discriminative ones.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	3.3 Comparison similar approaches: compara­.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	CogNIAC successfully resolved pronouns 75% cases.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	result comparable results described (Baldwin 1997).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	"languages attractive feature NLP approach would language ""universality""."	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	time being, using scores Polish.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	preference-based approach showed clear su­ periority baseline models.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
We implemented meta-modules to inÂ­ terface to the genetic algorithm driver and to combine different salience factors into an overÂ­ all score (similar to (Carbonell and Brown, 1988; Mitkov, 1998)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Robust pronoun resolution limited knowledge	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Input checked agreement number antecedent indicators.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	immediate reference identified, priority given candi date best collocation pattern score.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	help, candidate higher score indicating verbs preferred.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	still choice possible, recent remaining candi­ dates selected antecedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	2.1 Antecedent indicators.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	following shall outline indicators used shall illustrate ex­ amples.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	new information, rheme, provides information theme.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	preference explained terms sali­ ence point view centering theory.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Example: Press keyi turn volume up...	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Press iti again.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	preference viewed modification collocation preference.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	also quite fre­ quent imperative constructions.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Example: print paper, stand printeri lay iti flat.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	turn printer, press Power buttoni hold iti moment.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Unwrap paperi• form iti align iti• load iti drawer.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	21dentification clauses complex sentences e heuristically.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	scores determined experimentally empirical basis constantly up­ dated.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	point antecedent indicators preferences absolute factors.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"might cases one antecedent indicators ""point"" correct antecedent."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	2.2 Informal description algorithm.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Examine current sentence two pre­.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	ceding sentences (if available).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Look noun phrases3 left anaphor4 2.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Select noun phrases identified only.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	agree gender numberS pronominal anaphor group set potential candidates	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	antecedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	immediate reference hold, propose candidate higher score collocational pattern.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	indicator hold again, go recent candidate.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	3.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Evaluation.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evaluation, however, suggests much less lost might feared.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	resolution anaphors carried suc­ cess rate 95.8%.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Example: Identify draweq lit paper port LED add paper itj.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evaluation indicated 83.6% success rate.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evaluation estab­ lished critical success rate 82%.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	7 % 31.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	expected, frequent indica­ tors discriminative ones.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	3.3 Comparison similar approaches: compara­.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	CogNIAC successfully resolved pronouns 75% cases.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	result comparable results described (Baldwin 1997).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	"languages attractive feature NLP approach would language ""universality""."	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	time being, using scores Polish.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	preference-based approach showed clear su­ periority baseline models.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The current version of the system includes an implementation of the MARS pronoun resolution algorithm (Mitkov, 1998)	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Robust pronoun resolution limited knowledge	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Input checked agreement number antecedent indicators.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	immediate reference identified, priority given candi date best collocation pattern score.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	help, candidate higher score indicating verbs preferred.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	still choice possible, recent remaining candi­ dates selected antecedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	2.1 Antecedent indicators.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	following shall outline indicators used shall illustrate ex­ amples.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	new information, rheme, provides information theme.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	preference explained terms sali­ ence point view centering theory.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Example: Press keyi turn volume up...	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Press iti again.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	preference viewed modification collocation preference.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	also quite fre­ quent imperative constructions.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Example: print paper, stand printeri lay iti flat.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	turn printer, press Power buttoni hold iti moment.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Unwrap paperi• form iti align iti• load iti drawer.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	21dentification clauses complex sentences e heuristically.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	scores determined experimentally empirical basis constantly up­ dated.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	point antecedent indicators preferences absolute factors.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"might cases one antecedent indicators ""point"" correct antecedent."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	2.2 Informal description algorithm.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Examine current sentence two pre­.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	ceding sentences (if available).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Look noun phrases3 left anaphor4 2.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Select noun phrases identified only.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	agree gender numberS pronominal anaphor group set potential candidates	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	antecedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	immediate reference hold, propose candidate higher score collocational pattern.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	indicator hold again, go recent candidate.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	3.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Evaluation.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evaluation, however, suggests much less lost might feared.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	resolution anaphors carried suc­ cess rate 95.8%.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Example: Identify draweq lit paper port LED add paper itj.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evaluation indicated 83.6% success rate.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evaluation estab­ lished critical success rate 82%.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	7 % 31.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	expected, frequent indica­ tors discriminative ones.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	3.3 Comparison similar approaches: compara­.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	CogNIAC successfully resolved pronouns 75% cases.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	result comparable results described (Baldwin 1997).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	"languages attractive feature NLP approach would language ""universality""."	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	time being, using scores Polish.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	preference-based approach showed clear su­ periority baseline models.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
3.2.1 Pronoun Resolution Mitkov (1998) developed a robust approach to pronoun resolution which only requires input text to be part-of-speech tagged and noun phrases to be identified.  Mitkovâ€™s algorithm operates on the basis of antecedent-tracking preferences (referred to hereafter as â€antecedent indicatorsâ€).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	2.1 Antecedent indicators.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	new information, rheme, provides information theme.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Example: Press keyi turn volume up...	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Press iti again.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	preference viewed modification collocation preference.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	2.2 Informal description algorithm.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Examine current sentence two pre­.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	ceding sentences (if available).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Select noun phrases identified only.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	antecedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	indicator hold again, go recent candidate.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	3.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Evaluation.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	7 % 31.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	time being, using scores Polish.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The approach works as follows: the system identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor, and then applies genre- specific antecedent indicators to the remaining candidates (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Robust pronoun resolution limited knowledge	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Input checked agreement number antecedent indicators.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	immediate reference identified, priority given candi date best collocation pattern score.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	help, candidate higher score indicating verbs preferred.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	still choice possible, recent remaining candi­ dates selected antecedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	2.1 Antecedent indicators.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	following shall outline indicators used shall illustrate ex­ amples.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	new information, rheme, provides information theme.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	preference explained terms sali­ ence point view centering theory.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Example: Press keyi turn volume up...	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Press iti again.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	preference viewed modification collocation preference.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	also quite fre­ quent imperative constructions.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Example: print paper, stand printeri lay iti flat.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	turn printer, press Power buttoni hold iti moment.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Unwrap paperi• form iti align iti• load iti drawer.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	21dentification clauses complex sentences e heuristically.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	scores determined experimentally empirical basis constantly up­ dated.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	point antecedent indicators preferences absolute factors.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"might cases one antecedent indicators ""point"" correct antecedent."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	2.2 Informal description algorithm.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Examine current sentence two pre­.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	ceding sentences (if available).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Look noun phrases3 left anaphor4 2.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Select noun phrases identified only.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	agree gender numberS pronominal anaphor group set potential candidates	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	antecedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	immediate reference hold, propose candidate higher score collocational pattern.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	indicator hold again, go recent candidate.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	3.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Evaluation.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evaluation, however, suggests much less lost might feared.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	resolution anaphors carried suc­ cess rate 95.8%.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Example: Identify draweq lit paper port LED add paper itj.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evaluation indicated 83.6% success rate.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evaluation estab­ lished critical success rate 82%.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	7 % 31.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	expected, frequent indica­ tors discriminative ones.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	3.3 Comparison similar approaches: compara­.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	CogNIAC successfully resolved pronouns 75% cases.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	result comparable results described (Baldwin 1997).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	"languages attractive feature NLP approach would language ""universality""."	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	time being, using scores Polish.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	preference-based approach showed clear su­ periority baseline models.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
These feature functions bear similarity to rules used in other coreference systems (Lappin and Leass, 1994; Mitkov, 1998; Stuckardt, 2001), except that the feature weights {λi} are automatically trained over a corpus with coreference information.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Robust pronoun resolution limited knowledge	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Input checked agreement number antecedent indicators.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	immediate reference identified, priority given candi date best collocation pattern score.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	help, candidate higher score indicating verbs preferred.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	still choice possible, recent remaining candi­ dates selected antecedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	2.1 Antecedent indicators.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	following shall outline indicators used shall illustrate ex­ amples.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	new information, rheme, provides information theme.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	preference explained terms sali­ ence point view centering theory.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Example: Press keyi turn volume up...	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Press iti again.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	preference viewed modification collocation preference.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	also quite fre­ quent imperative constructions.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Example: print paper, stand printeri lay iti flat.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	turn printer, press Power buttoni hold iti moment.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Unwrap paperi• form iti align iti• load iti drawer.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	21dentification clauses complex sentences e heuristically.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	scores determined experimentally empirical basis constantly up­ dated.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	point antecedent indicators preferences absolute factors.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"might cases one antecedent indicators ""point"" correct antecedent."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	2.2 Informal description algorithm.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Examine current sentence two pre­.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	ceding sentences (if available).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Look noun phrases3 left anaphor4 2.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Select noun phrases identified only.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	agree gender numberS pronominal anaphor group set potential candidates	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	antecedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	immediate reference hold, propose candidate higher score collocational pattern.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	indicator hold again, go recent candidate.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	3.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Evaluation.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evaluation, however, suggests much less lost might feared.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	resolution anaphors carried suc­ cess rate 95.8%.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Example: Identify draweq lit paper port LED add paper itj.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evaluation indicated 83.6% success rate.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evaluation estab­ lished critical success rate 82%.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	7 % 31.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	expected, frequent indica­ tors discriminative ones.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	3.3 Comparison similar approaches: compara­.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	CogNIAC successfully resolved pronouns 75% cases.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	result comparable results described (Baldwin 1997).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	"languages attractive feature NLP approach would language ""universality""."	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	time being, using scores Polish.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	preference-based approach showed clear su­ periority baseline models.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
F-measure here is more stringent than the accuracy (Ge et al., 1998; Mitkov, 1998; Kehler et al., 2004) computed on antecedent-pronoun pairs.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Robust pronoun resolution limited knowledge	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Input checked agreement number antecedent indicators.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	immediate reference identified, priority given candi date best collocation pattern score.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	help, candidate higher score indicating verbs preferred.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	2.1 Antecedent indicators.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	following shall outline indicators used shall illustrate ex­ amples.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	new information, rheme, provides information theme.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	preference explained terms sali­ ence point view centering theory.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Example: Press keyi turn volume up...	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Press iti again.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	preference viewed modification collocation preference.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	also quite fre­ quent imperative constructions.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Example: print paper, stand printeri lay iti flat.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	turn printer, press Power buttoni hold iti moment.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Unwrap paperi• form iti align iti• load iti drawer.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	21dentification clauses complex sentences e heuristically.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	scores determined experimentally empirical basis constantly up­ dated.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	point antecedent indicators preferences absolute factors.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	2.2 Informal description algorithm.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Examine current sentence two pre­.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	ceding sentences (if available).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Look noun phrases3 left anaphor4 2.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Select noun phrases identified only.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	agree gender numberS pronominal anaphor group set potential candidates	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	antecedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	immediate reference hold, propose candidate higher score collocational pattern.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	indicator hold again, go recent candidate.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	3.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Evaluation.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evaluation, however, suggests much less lost might feared.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	resolution anaphors carried suc­ cess rate 95.8%.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Example: Identify draweq lit paper port LED add paper itj.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evaluation indicated 83.6% success rate.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evaluation estab­ lished critical success rate 82%.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	7 % 31.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	expected, frequent indica­ tors discriminative ones.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	3.3 Comparison similar approaches: compara­.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	CogNIAC successfully resolved pronouns 75% cases.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	result comparable results described (Baldwin 1997).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	"languages attractive feature NLP approach would language ""universality""."	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	time being, using scores Polish.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	preference-based approach showed clear su­ periority baseline models.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Robust pronoun resolution limited knowledge	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Input checked agreement number antecedent indicators.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	immediate reference identified, priority given candi date best collocation pattern score.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	help, candidate higher score indicating verbs preferred.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	2.1 Antecedent indicators.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	following shall outline indicators used shall illustrate ex­ amples.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	new information, rheme, provides information theme.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	preference explained terms sali­ ence point view centering theory.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Example: Press keyi turn volume up...	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Press iti again.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	preference viewed modification collocation preference.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	also quite fre­ quent imperative constructions.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Example: print paper, stand printeri lay iti flat.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	turn printer, press Power buttoni hold iti moment.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Unwrap paperi• form iti align iti• load iti drawer.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	21dentification clauses complex sentences e heuristically.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	scores determined experimentally empirical basis constantly up­ dated.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	point antecedent indicators preferences absolute factors.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	2.2 Informal description algorithm.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Examine current sentence two pre­.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	ceding sentences (if available).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Look noun phrases3 left anaphor4 2.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Select noun phrases identified only.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	agree gender numberS pronominal anaphor group set potential candidates	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	antecedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	immediate reference hold, propose candidate higher score collocational pattern.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	indicator hold again, go recent candidate.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	3.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Evaluation.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evaluation, however, suggests much less lost might feared.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	resolution anaphors carried suc­ cess rate 95.8%.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Example: Identify draweq lit paper port LED add paper itj.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evaluation indicated 83.6% success rate.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evaluation estab­ lished critical success rate 82%.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	7 % 31.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	expected, frequent indica­ tors discriminative ones.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	3.3 Comparison similar approaches: compara­.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	CogNIAC successfully resolved pronouns 75% cases.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	result comparable results described (Baldwin 1997).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	"languages attractive feature NLP approach would language ""universality""."	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	time being, using scores Polish.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	preference-based approach showed clear su­ periority baseline models.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Robust pronoun resolution limited knowledge	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Input checked agreement number antecedent indicators.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	immediate reference identified, priority given candi date best collocation pattern score.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	help, candidate higher score indicating verbs preferred.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	still choice possible, recent remaining candi­ dates selected antecedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	2.1 Antecedent indicators.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	following shall outline indicators used shall illustrate ex­ amples.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	new information, rheme, provides information theme.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	preference explained terms sali­ ence point view centering theory.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Example: Press keyi turn volume up...	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Press iti again.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	preference viewed modification collocation preference.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	also quite fre­ quent imperative constructions.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Example: print paper, stand printeri lay iti flat.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	turn printer, press Power buttoni hold iti moment.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Unwrap paperi• form iti align iti• load iti drawer.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	21dentification clauses complex sentences e heuristically.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	scores determined experimentally empirical basis constantly up­ dated.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	point antecedent indicators preferences absolute factors.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"might cases one antecedent indicators ""point"" correct antecedent."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	2.2 Informal description algorithm.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Examine current sentence two pre­.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	ceding sentences (if available).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Look noun phrases3 left anaphor4 2.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Select noun phrases identified only.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	agree gender numberS pronominal anaphor group set potential candidates	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	antecedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	immediate reference hold, propose candidate higher score collocational pattern.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	indicator hold again, go recent candidate.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	3.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Evaluation.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evaluation, however, suggests much less lost might feared.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	resolution anaphors carried suc­ cess rate 95.8%.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Example: Identify draweq lit paper port LED add paper itj.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evaluation indicated 83.6% success rate.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evaluation estab­ lished critical success rate 82%.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	7 % 31.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	expected, frequent indica­ tors discriminative ones.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	3.3 Comparison similar approaches: compara­.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	CogNIAC successfully resolved pronouns 75% cases.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	result comparable results described (Baldwin 1997).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	"languages attractive feature NLP approach would language ""universality""."	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	time being, using scores Polish.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	preference-based approach showed clear su­ periority baseline models.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
A lot of work has been done in English for the purpose of anaphora resolution and various   algorithms have been devised for this purpose (Aone and Bennette, 1996; Brenan , Friedman and Pollard, 1987; Ge, Hale and Charniak, 1998; Grosz, Aravind and Weinstein, 1995; McCarthy and Lehnert, 1995; Lappins and Leass, 1994; Mitkov, 1998; Soon, Ng and Lim, 1999).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Robust pronoun resolution limited knowledge	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Input checked agreement number antecedent indicators.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	immediate reference identified, priority given candi date best collocation pattern score.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	help, candidate higher score indicating verbs preferred.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	still choice possible, recent remaining candi­ dates selected antecedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	2.1 Antecedent indicators.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	following shall outline indicators used shall illustrate ex­ amples.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	new information, rheme, provides information theme.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	preference explained terms sali­ ence point view centering theory.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Example: Press keyi turn volume up...	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Press iti again.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	preference viewed modification collocation preference.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	also quite fre­ quent imperative constructions.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Example: print paper, stand printeri lay iti flat.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	turn printer, press Power buttoni hold iti moment.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Unwrap paperi• form iti align iti• load iti drawer.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	21dentification clauses complex sentences e heuristically.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	scores determined experimentally empirical basis constantly up­ dated.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	point antecedent indicators preferences absolute factors.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"might cases one antecedent indicators ""point"" correct antecedent."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	2.2 Informal description algorithm.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Examine current sentence two pre­.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	ceding sentences (if available).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Look noun phrases3 left anaphor4 2.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Select noun phrases identified only.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	agree gender numberS pronominal anaphor group set potential candidates	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	antecedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	immediate reference hold, propose candidate higher score collocational pattern.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	indicator hold again, go recent candidate.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	3.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Evaluation.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evaluation, however, suggests much less lost might feared.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	resolution anaphors carried suc­ cess rate 95.8%.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Example: Identify draweq lit paper port LED add paper itj.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evaluation indicated 83.6% success rate.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evaluation estab­ lished critical success rate 82%.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	7 % 31.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	expected, frequent indica­ tors discriminative ones.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	3.3 Comparison similar approaches: compara­.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	CogNIAC successfully resolved pronouns 75% cases.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	result comparable results described (Baldwin 1997).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	"languages attractive feature NLP approach would language ""universality""."	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	time being, using scores Polish.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	preference-based approach showed clear su­ periority baseline models.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
How these factors are helpful in anaphora resolution in English language was worked out by Mitkov (Mitkov, 1998), but their role in Urdu discourse for the resolution of personal pronouns is more cherished.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Robust pronoun resolution limited knowledge	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Input checked agreement number antecedent indicators.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	immediate reference identified, priority given candi date best collocation pattern score.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	help, candidate higher score indicating verbs preferred.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	2.1 Antecedent indicators.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	following shall outline indicators used shall illustrate ex­ amples.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	new information, rheme, provides information theme.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	preference explained terms sali­ ence point view centering theory.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Example: Press keyi turn volume up...	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Press iti again.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	preference viewed modification collocation preference.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	also quite fre­ quent imperative constructions.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Example: print paper, stand printeri lay iti flat.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	turn printer, press Power buttoni hold iti moment.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Unwrap paperi• form iti align iti• load iti drawer.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	21dentification clauses complex sentences e heuristically.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	scores determined experimentally empirical basis constantly up­ dated.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	point antecedent indicators preferences absolute factors.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	2.2 Informal description algorithm.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Examine current sentence two pre­.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	ceding sentences (if available).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Look noun phrases3 left anaphor4 2.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Select noun phrases identified only.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	agree gender numberS pronominal anaphor group set potential candidates	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	antecedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	immediate reference hold, propose candidate higher score collocational pattern.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	indicator hold again, go recent candidate.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	3.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Evaluation.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evaluation, however, suggests much less lost might feared.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	resolution anaphors carried suc­ cess rate 95.8%.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Example: Identify draweq lit paper port LED add paper itj.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evaluation indicated 83.6% success rate.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evaluation estab­ lished critical success rate 82%.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	7 % 31.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	expected, frequent indica­ tors discriminative ones.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	3.3 Comparison similar approaches: compara­.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	CogNIAC successfully resolved pronouns 75% cases.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	result comparable results described (Baldwin 1997).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	"languages attractive feature NLP approach would language ""universality""."	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	time being, using scores Polish.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	preference-based approach showed clear su­ periority baseline models.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Many hand-tested corpus evaluations have been done in the past (e.g., Walker 1989; Strube 1998; Mitkov 1998; Strube and Hahn 1999), but these have the drawback of being carried out on small corpora.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Robust pronoun resolution limited knowledge	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Input checked agreement number antecedent indicators.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	immediate reference identified, priority given candi date best collocation pattern score.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	help, candidate higher score indicating verbs preferred.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	2.1 Antecedent indicators.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	following shall outline indicators used shall illustrate ex­ amples.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	new information, rheme, provides information theme.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	preference explained terms sali­ ence point view centering theory.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Example: Press keyi turn volume up...	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Press iti again.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	preference viewed modification collocation preference.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	also quite fre­ quent imperative constructions.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Example: print paper, stand printeri lay iti flat.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	turn printer, press Power buttoni hold iti moment.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Unwrap paperi• form iti align iti• load iti drawer.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	21dentification clauses complex sentences e heuristically.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	scores determined experimentally empirical basis constantly up­ dated.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	point antecedent indicators preferences absolute factors.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	2.2 Informal description algorithm.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Examine current sentence two pre­.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	ceding sentences (if available).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Look noun phrases3 left anaphor4 2.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Select noun phrases identified only.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	agree gender numberS pronominal anaphor group set potential candidates	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	antecedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	immediate reference hold, propose candidate higher score collocational pattern.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	indicator hold again, go recent candidate.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	3.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Evaluation.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evaluation, however, suggests much less lost might feared.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	resolution anaphors carried suc­ cess rate 95.8%.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Example: Identify draweq lit paper port LED add paper itj.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evaluation indicated 83.6% success rate.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evaluation estab­ lished critical success rate 82%.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	7 % 31.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	expected, frequent indica­ tors discriminative ones.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	3.3 Comparison similar approaches: compara­.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	CogNIAC successfully resolved pronouns 75% cases.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	result comparable results described (Baldwin 1997).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	"languages attractive feature NLP approach would language ""universality""."	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	time being, using scores Polish.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	preference-based approach showed clear su­ periority baseline models.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Consequently, current anaphora resolution methods rely mainly on constraint and preference heuristics, which employ morpho-syntactic information or shallow semantic analysis (see, for example, Mitkov [1998]).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Robust pronoun resolution limited knowledge	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Input checked agreement number antecedent indicators.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	immediate reference identified, priority given candi date best collocation pattern score.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	help, candidate higher score indicating verbs preferred.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	2.1 Antecedent indicators.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	following shall outline indicators used shall illustrate ex­ amples.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	new information, rheme, provides information theme.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	preference explained terms sali­ ence point view centering theory.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Example: Press keyi turn volume up...	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Press iti again.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	preference viewed modification collocation preference.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	also quite fre­ quent imperative constructions.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Example: print paper, stand printeri lay iti flat.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	turn printer, press Power buttoni hold iti moment.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Unwrap paperi• form iti align iti• load iti drawer.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	21dentification clauses complex sentences e heuristically.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	scores determined experimentally empirical basis constantly up­ dated.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	point antecedent indicators preferences absolute factors.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	2.2 Informal description algorithm.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Examine current sentence two pre­.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	ceding sentences (if available).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Look noun phrases3 left anaphor4 2.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Select noun phrases identified only.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	agree gender numberS pronominal anaphor group set potential candidates	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	antecedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	immediate reference hold, propose candidate higher score collocational pattern.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	indicator hold again, go recent candidate.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	3.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Evaluation.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evaluation, however, suggests much less lost might feared.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	1
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	resolution anaphors carried suc­ cess rate 95.8%.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Example: Identify draweq lit paper port LED add paper itj.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evaluation indicated 83.6% success rate.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evaluation estab­ lished critical success rate 82%.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	7 % 31.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	expected, frequent indica­ tors discriminative ones.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	3.3 Comparison similar approaches: compara­.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	CogNIAC successfully resolved pronouns 75% cases.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	result comparable results described (Baldwin 1997).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	"languages attractive feature NLP approach would language ""universality""."	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	time being, using scores Polish.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	preference-based approach showed clear su­ periority baseline models.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Exa mple s: (we athe r) It is raini ng, (tim e) It is 5 o&apos;clo ck, and (am bien t envi ron men t) It is hot in here . reports provide no exclusion details at all, and even when authors do provide them, the descriptions they use are often incomplete or confusing, as in these examples: â€¢ &quot;7 of the pronouns were non-anaphoric and 16 exophoric&quot; (Mitkov 1998, page 872).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Robust pronoun resolution limited knowledge	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Input checked agreement number antecedent indicators.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	immediate reference identified, priority given candi date best collocation pattern score.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	help, candidate higher score indicating verbs preferred.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	2.1 Antecedent indicators.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	following shall outline indicators used shall illustrate ex­ amples.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	new information, rheme, provides information theme.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	preference explained terms sali­ ence point view centering theory.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Example: Press keyi turn volume up...	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Press iti again.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	preference viewed modification collocation preference.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	also quite fre­ quent imperative constructions.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Example: print paper, stand printeri lay iti flat.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	turn printer, press Power buttoni hold iti moment.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Unwrap paperi• form iti align iti• load iti drawer.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	21dentification clauses complex sentences e heuristically.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	scores determined experimentally empirical basis constantly up­ dated.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	point antecedent indicators preferences absolute factors.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	2.2 Informal description algorithm.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Examine current sentence two pre­.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	ceding sentences (if available).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Look noun phrases3 left anaphor4 2.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Select noun phrases identified only.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	agree gender numberS pronominal anaphor group set potential candidates	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	antecedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	immediate reference hold, propose candidate higher score collocational pattern.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	indicator hold again, go recent candidate.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	3.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Evaluation.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evaluation, however, suggests much less lost might feared.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	resolution anaphors carried suc­ cess rate 95.8%.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Example: Identify draweq lit paper port LED add paper itj.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evaluation indicated 83.6% success rate.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evaluation estab­ lished critical success rate 82%.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	7 % 31.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	expected, frequent indica­ tors discriminative ones.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	3.3 Comparison similar approaches: compara­.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	CogNIAC successfully resolved pronouns 75% cases.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	result comparable results described (Baldwin 1997).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	"languages attractive feature NLP approach would language ""universality""."	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	time being, using scores Polish.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	preference-based approach showed clear su­ periority baseline models.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Robust pronoun resolution limited knowledge	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Input checked agreement number antecedent indicators.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	immediate reference identified, priority given candi date best collocation pattern score.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	help, candidate higher score indicating verbs preferred.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	2.1 Antecedent indicators.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	following shall outline indicators used shall illustrate ex­ amples.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	new information, rheme, provides information theme.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	preference explained terms sali­ ence point view centering theory.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Example: Press keyi turn volume up...	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Press iti again.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	preference viewed modification collocation preference.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	also quite fre­ quent imperative constructions.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Example: print paper, stand printeri lay iti flat.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	turn printer, press Power buttoni hold iti moment.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Unwrap paperi• form iti align iti• load iti drawer.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	21dentification clauses complex sentences e heuristically.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	scores determined experimentally empirical basis constantly up­ dated.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	point antecedent indicators preferences absolute factors.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	2.2 Informal description algorithm.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Examine current sentence two pre­.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	ceding sentences (if available).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Look noun phrases3 left anaphor4 2.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Select noun phrases identified only.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	agree gender numberS pronominal anaphor group set potential candidates	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	antecedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	immediate reference hold, propose candidate higher score collocational pattern.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	indicator hold again, go recent candidate.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	3.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Evaluation.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evaluation, however, suggests much less lost might feared.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	resolution anaphors carried suc­ cess rate 95.8%.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Example: Identify draweq lit paper port LED add paper itj.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evaluation indicated 83.6% success rate.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evaluation estab­ lished critical success rate 82%.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	7 % 31.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	expected, frequent indica­ tors discriminative ones.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	3.3 Comparison similar approaches: compara­.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	CogNIAC successfully resolved pronouns 75% cases.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	result comparable results described (Baldwin 1997).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	"languages attractive feature NLP approach would language ""universality""."	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	time being, using scores Polish.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	preference-based approach showed clear su­ periority baseline models.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.  Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Robust pronoun resolution limited knowledge	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Input checked agreement number antecedent indicators.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	immediate reference identified, priority given candi date best collocation pattern score.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	help, candidate higher score indicating verbs preferred.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	2.1 Antecedent indicators.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	following shall outline indicators used shall illustrate ex­ amples.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	new information, rheme, provides information theme.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	preference explained terms sali­ ence point view centering theory.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Example: Press keyi turn volume up...	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Press iti again.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	preference viewed modification collocation preference.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	also quite fre­ quent imperative constructions.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Example: print paper, stand printeri lay iti flat.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	turn printer, press Power buttoni hold iti moment.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Unwrap paperi• form iti align iti• load iti drawer.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	21dentification clauses complex sentences e heuristically.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	scores determined experimentally empirical basis constantly up­ dated.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	point antecedent indicators preferences absolute factors.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	2.2 Informal description algorithm.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Examine current sentence two pre­.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	ceding sentences (if available).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Look noun phrases3 left anaphor4 2.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Select noun phrases identified only.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	agree gender numberS pronominal anaphor group set potential candidates	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	antecedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	immediate reference hold, propose candidate higher score collocational pattern.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	indicator hold again, go recent candidate.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	3.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Evaluation.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evaluation, however, suggests much less lost might feared.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	resolution anaphors carried suc­ cess rate 95.8%.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Example: Identify draweq lit paper port LED add paper itj.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evaluation indicated 83.6% success rate.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evaluation estab­ lished critical success rate 82%.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	7 % 31.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	expected, frequent indica­ tors discriminative ones.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	3.3 Comparison similar approaches: compara­.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	CogNIAC successfully resolved pronouns 75% cases.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	result comparable results described (Baldwin 1997).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	"languages attractive feature NLP approach would language ""universality""."	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	time being, using scores Polish.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	preference-based approach showed clear su­ periority baseline models.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The acquisition of exten sive linguistic and discourse knowledge necessaryfor resolving coreference is time consuming, diffi cult and error-prone.  Neverthless, recent resultsshow that knowledge-poor, empirical methods per form with amazing accuracy on certain forms ofcoreference (cf.  (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Robust pronoun resolution limited knowledge	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Input checked agreement number antecedent indicators.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	immediate reference identified, priority given candi date best collocation pattern score.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	help, candidate higher score indicating verbs preferred.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	2.1 Antecedent indicators.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	following shall outline indicators used shall illustrate ex­ amples.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	new information, rheme, provides information theme.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	preference explained terms sali­ ence point view centering theory.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Example: Press keyi turn volume up...	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Press iti again.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	preference viewed modification collocation preference.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	also quite fre­ quent imperative constructions.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Example: print paper, stand printeri lay iti flat.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	turn printer, press Power buttoni hold iti moment.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Unwrap paperi• form iti align iti• load iti drawer.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	21dentification clauses complex sentences e heuristically.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	scores determined experimentally empirical basis constantly up­ dated.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	point antecedent indicators preferences absolute factors.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	2.2 Informal description algorithm.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Examine current sentence two pre­.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	ceding sentences (if available).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Look noun phrases3 left anaphor4 2.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Select noun phrases identified only.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	agree gender numberS pronominal anaphor group set potential candidates	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	antecedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	immediate reference hold, propose candidate higher score collocational pattern.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	indicator hold again, go recent candidate.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	3.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Evaluation.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evaluation, however, suggests much less lost might feared.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	resolution anaphors carried suc­ cess rate 95.8%.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Example: Identify draweq lit paper port LED add paper itj.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evaluation indicated 83.6% success rate.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evaluation estab­ lished critical success rate 82%.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	7 % 31.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	expected, frequent indica­ tors discriminative ones.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	3.3 Comparison similar approaches: compara­.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	CogNIAC successfully resolved pronouns 75% cases.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	result comparable results described (Baldwin 1997).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	"languages attractive feature NLP approach would language ""universality""."	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	time being, using scores Polish.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	preference-based approach showed clear su­ periority baseline models.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCK TAIL filters its most performant rules through massivetraining data, generated by its AUTOTAGCOFtEF com ponent.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	2.1 Antecedent indicators.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	new information, rheme, provides information theme.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Example: Press keyi turn volume up...	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Press iti again.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	preference viewed modification collocation preference.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	2.2 Informal description algorithm.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Examine current sentence two pre­.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	ceding sentences (if available).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Select noun phrases identified only.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	antecedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	indicator hold again, go recent candidate.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	3.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Evaluation.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	7 % 31.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	time being, using scores Polish.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Mitkov showed that a salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Robust pronoun resolution limited knowledge	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Input checked agreement number antecedent indicators.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	immediate reference identified, priority given candi date best collocation pattern score.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	help, candidate higher score indicating verbs preferred.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	2.1 Antecedent indicators.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	following shall outline indicators used shall illustrate ex­ amples.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	new information, rheme, provides information theme.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	preference explained terms sali­ ence point view centering theory.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Example: Press keyi turn volume up...	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Press iti again.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	preference viewed modification collocation preference.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	also quite fre­ quent imperative constructions.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Example: print paper, stand printeri lay iti flat.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	turn printer, press Power buttoni hold iti moment.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Unwrap paperi• form iti align iti• load iti drawer.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	21dentification clauses complex sentences e heuristically.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	scores determined experimentally empirical basis constantly up­ dated.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	point antecedent indicators preferences absolute factors.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	2.2 Informal description algorithm.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Examine current sentence two pre­.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	ceding sentences (if available).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Look noun phrases3 left anaphor4 2.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Select noun phrases identified only.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	agree gender numberS pronominal anaphor group set potential candidates	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	antecedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	immediate reference hold, propose candidate higher score collocational pattern.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	indicator hold again, go recent candidate.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	3.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Evaluation.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evaluation, however, suggests much less lost might feared.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	resolution anaphors carried suc­ cess rate 95.8%.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Example: Identify draweq lit paper port LED add paper itj.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evaluation indicated 83.6% success rate.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evaluation estab­ lished critical success rate 82%.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	7 % 31.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	expected, frequent indica­ tors discriminative ones.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	3.3 Comparison similar approaches: compara­.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	CogNIAC successfully resolved pronouns 75% cases.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	result comparable results described (Baldwin 1997).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	"languages attractive feature NLP approach would language ""universality""."	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	time being, using scores Polish.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	preference-based approach showed clear su­ periority baseline models.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Consequently, current anaphora resolution methods rely mainly on restrictions and preference heuristics, which employ information originating from morpho-syntactic or shallow semantic analysis, (see Mitkov (1998) for example).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Robust pronoun resolution limited knowledge	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Input checked agreement number antecedent indicators.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	immediate reference identified, priority given candi date best collocation pattern score.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	help, candidate higher score indicating verbs preferred.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	2.1 Antecedent indicators.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	following shall outline indicators used shall illustrate ex­ amples.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	new information, rheme, provides information theme.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	preference explained terms sali­ ence point view centering theory.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Example: Press keyi turn volume up...	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Press iti again.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	preference viewed modification collocation preference.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	also quite fre­ quent imperative constructions.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Example: print paper, stand printeri lay iti flat.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	turn printer, press Power buttoni hold iti moment.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Unwrap paperi• form iti align iti• load iti drawer.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	21dentification clauses complex sentences e heuristically.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	scores determined experimentally empirical basis constantly up­ dated.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	point antecedent indicators preferences absolute factors.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	2.2 Informal description algorithm.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Examine current sentence two pre­.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	ceding sentences (if available).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Look noun phrases3 left anaphor4 2.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Select noun phrases identified only.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	agree gender numberS pronominal anaphor group set potential candidates	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	antecedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	immediate reference hold, propose candidate higher score collocational pattern.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	indicator hold again, go recent candidate.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	3.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Evaluation.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evaluation, however, suggests much less lost might feared.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	resolution anaphors carried suc­ cess rate 95.8%.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Example: Identify draweq lit paper port LED add paper itj.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evaluation indicated 83.6% success rate.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evaluation estab­ lished critical success rate 82%.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	7 % 31.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	expected, frequent indica­ tors discriminative ones.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	3.3 Comparison similar approaches: compara­.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	CogNIAC successfully resolved pronouns 75% cases.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	result comparable results described (Baldwin 1997).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	"languages attractive feature NLP approach would language ""universality""."	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	time being, using scores Polish.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	preference-based approach showed clear su­ periority baseline models.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Mitkov (1998) obtains a success rate of 89.7% for pronominal references, working with English technical manuals.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Robust pronoun resolution limited knowledge	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Input checked agreement number antecedent indicators.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	immediate reference identified, priority given candi date best collocation pattern score.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	help, candidate higher score indicating verbs preferred.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	2.1 Antecedent indicators.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	following shall outline indicators used shall illustrate ex­ amples.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	new information, rheme, provides information theme.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	preference explained terms sali­ ence point view centering theory.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Example: Press keyi turn volume up...	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Press iti again.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	preference viewed modification collocation preference.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	also quite fre­ quent imperative constructions.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Example: print paper, stand printeri lay iti flat.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	turn printer, press Power buttoni hold iti moment.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Unwrap paperi• form iti align iti• load iti drawer.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	21dentification clauses complex sentences e heuristically.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	scores determined experimentally empirical basis constantly up­ dated.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	point antecedent indicators preferences absolute factors.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	2.2 Informal description algorithm.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Examine current sentence two pre­.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	ceding sentences (if available).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Look noun phrases3 left anaphor4 2.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Select noun phrases identified only.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	agree gender numberS pronominal anaphor group set potential candidates	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	antecedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	immediate reference hold, propose candidate higher score collocational pattern.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	indicator hold again, go recent candidate.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	3.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Evaluation.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evaluation, however, suggests much less lost might feared.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	resolution anaphors carried suc­ cess rate 95.8%.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Example: Identify draweq lit paper port LED add paper itj.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evaluation indicated 83.6% success rate.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evaluation estab­ lished critical success rate 82%.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	7 % 31.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	expected, frequent indica­ tors discriminative ones.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	3.3 Comparison similar approaches: compara­.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	CogNIAC successfully resolved pronouns 75% cases.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	result comparable results described (Baldwin 1997).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	"languages attractive feature NLP approach would language ""universality""."	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	time being, using scores Polish.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	preference-based approach showed clear su­ periority baseline models.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Ruslan Mitkov (1998) Robust pronoun resolution th evaluation, several baselines on pronominal anaphora resolution have been implemented, and with limited knowledge.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Robust pronoun resolution limited knowledge	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Input checked agreement number antecedent indicators.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	immediate reference identified, priority given candi date best collocation pattern score.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	help, candidate higher score indicating verbs preferred.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	still choice possible, recent remaining candi­ dates selected antecedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	2.1 Antecedent indicators.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	following shall outline indicators used shall illustrate ex­ amples.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	new information, rheme, provides information theme.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	preference explained terms sali­ ence point view centering theory.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Example: Press keyi turn volume up...	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Press iti again.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	preference viewed modification collocation preference.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	also quite fre­ quent imperative constructions.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Example: print paper, stand printeri lay iti flat.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	turn printer, press Power buttoni hold iti moment.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Unwrap paperi• form iti align iti• load iti drawer.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	21dentification clauses complex sentences e heuristically.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	scores determined experimentally empirical basis constantly up­ dated.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	point antecedent indicators preferences absolute factors.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"might cases one antecedent indicators ""point"" correct antecedent."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	2.2 Informal description algorithm.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Examine current sentence two pre­.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	ceding sentences (if available).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Look noun phrases3 left anaphor4 2.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Select noun phrases identified only.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	agree gender numberS pronominal anaphor group set potential candidates	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	antecedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	immediate reference hold, propose candidate higher score collocational pattern.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	indicator hold again, go recent candidate.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	3.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Evaluation.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evaluation, however, suggests much less lost might feared.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	resolution anaphors carried suc­ cess rate 95.8%.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Example: Identify draweq lit paper port LED add paper itj.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evaluation indicated 83.6% success rate.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evaluation estab­ lished critical success rate 82%.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	7 % 31.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	expected, frequent indica­ tors discriminative ones.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	3.3 Comparison similar approaches: compara­.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	CogNIAC successfully resolved pronouns 75% cases.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	result comparable results described (Baldwin 1997).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	"languages attractive feature NLP approach would language ""universality""."	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	time being, using scores Polish.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	preference-based approach showed clear su­ periority baseline models.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	1
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
We selected for comparative evaluation three approaches extensively cited in the literature: Kennedy and Boguraevâ€™s parser- free version of Lappin and Leassâ€™ RAP (Kennedy and Boguraev, 1996), Baldwinâ€™s pronoun resolution method (Baldwin, 1997) and Mitkovâ€™s knowledge-poor pronoun resolution approach (Mitkov, 1998b).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Robust pronoun resolution limited knowledge	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Input checked agreement number antecedent indicators.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	immediate reference identified, priority given candi date best collocation pattern score.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	help, candidate higher score indicating verbs preferred.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	2.1 Antecedent indicators.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	following shall outline indicators used shall illustrate ex­ amples.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	new information, rheme, provides information theme.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	preference explained terms sali­ ence point view centering theory.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Example: Press keyi turn volume up...	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Press iti again.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	preference viewed modification collocation preference.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	also quite fre­ quent imperative constructions.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Example: print paper, stand printeri lay iti flat.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	turn printer, press Power buttoni hold iti moment.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Unwrap paperi• form iti align iti• load iti drawer.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	21dentification clauses complex sentences e heuristically.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	scores determined experimentally empirical basis constantly up­ dated.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	point antecedent indicators preferences absolute factors.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	2.2 Informal description algorithm.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Examine current sentence two pre­.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	ceding sentences (if available).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Look noun phrases3 left anaphor4 2.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Select noun phrases identified only.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	agree gender numberS pronominal anaphor group set potential candidates	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	antecedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	immediate reference hold, propose candidate higher score collocational pattern.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	indicator hold again, go recent candidate.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	3.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Evaluation.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evaluation, however, suggests much less lost might feared.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	resolution anaphors carried suc­ cess rate 95.8%.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Example: Identify draweq lit paper port LED add paper itj.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evaluation indicated 83.6% success rate.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evaluation estab­ lished critical success rate 82%.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	7 % 31.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	expected, frequent indica­ tors discriminative ones.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	3.3 Comparison similar approaches: compara­.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	CogNIAC successfully resolved pronouns 75% cases.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	result comparable results described (Baldwin 1997).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	"languages attractive feature NLP approach would language ""universality""."	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	time being, using scores Polish.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	preference-based approach showed clear su­ periority baseline models.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Mitkovâ€™s approach Mitkovâ€™s approach (Mitkov, 1998b) is a robust anaphora resolution method for technical texts which is based on a set of boosting and impeding indicators applied to each candidate for antecedent.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Robust pronoun resolution limited knowledge	1
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Input checked agreement number antecedent indicators.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	immediate reference identified, priority given candi date best collocation pattern score.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	help, candidate higher score indicating verbs preferred.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	still choice possible, recent remaining candi­ dates selected antecedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	2.1 Antecedent indicators.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	following shall outline indicators used shall illustrate ex­ amples.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	new information, rheme, provides information theme.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	preference explained terms sali­ ence point view centering theory.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Example: Press keyi turn volume up...	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Press iti again.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	preference viewed modification collocation preference.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	also quite fre­ quent imperative constructions.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Example: print paper, stand printeri lay iti flat.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	turn printer, press Power buttoni hold iti moment.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Unwrap paperi• form iti align iti• load iti drawer.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	21dentification clauses complex sentences e heuristically.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	scores determined experimentally empirical basis constantly up­ dated.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	point antecedent indicators preferences absolute factors.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"might cases one antecedent indicators ""point"" correct antecedent."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	2.2 Informal description algorithm.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Examine current sentence two pre­.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	ceding sentences (if available).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Look noun phrases3 left anaphor4 2.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Select noun phrases identified only.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	agree gender numberS pronominal anaphor group set potential candidates	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	antecedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	immediate reference hold, propose candidate higher score collocational pattern.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	indicator hold again, go recent candidate.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	3.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Evaluation.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evaluation, however, suggests much less lost might feared.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	resolution anaphors carried suc­ cess rate 95.8%.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Example: Identify draweq lit paper port LED add paper itj.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evaluation indicated 83.6% success rate.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evaluation estab­ lished critical success rate 82%.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	7 % 31.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	expected, frequent indica­ tors discriminative ones.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	3.3 Comparison similar approaches: compara­.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	CogNIAC successfully resolved pronouns 75% cases.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	result comparable results described (Baldwin 1997).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	"languages attractive feature NLP approach would language ""universality""."	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	time being, using scores Polish.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	preference-based approach showed clear su­ periority baseline models.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
pronouns, referential distance, average number of candidates for antecedent per pronoun and types of anaphors.7 As expected, the results reported in Table 1 do not match the original results published by Kennedy and Boguraev (1996), Baldwin (1997) and Mitkov (1998b) where the algorithms were tested on different data, employed different pre-processing tools, resorted to different degrees of manual intervention and thus provided no common ground for any reliable comparison.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Robust pronoun resolution limited knowledge	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Input checked agreement number antecedent indicators.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	immediate reference identified, priority given candi date best collocation pattern score.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	help, candidate higher score indicating verbs preferred.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	2.1 Antecedent indicators.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	following shall outline indicators used shall illustrate ex­ amples.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	new information, rheme, provides information theme.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	preference explained terms sali­ ence point view centering theory.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Example: Press keyi turn volume up...	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Press iti again.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	preference viewed modification collocation preference.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	also quite fre­ quent imperative constructions.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Example: print paper, stand printeri lay iti flat.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	turn printer, press Power buttoni hold iti moment.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Unwrap paperi• form iti align iti• load iti drawer.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	21dentification clauses complex sentences e heuristically.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	scores determined experimentally empirical basis constantly up­ dated.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	point antecedent indicators preferences absolute factors.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	2.2 Informal description algorithm.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Examine current sentence two pre­.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	ceding sentences (if available).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Look noun phrases3 left anaphor4 2.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Select noun phrases identified only.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	agree gender numberS pronominal anaphor group set potential candidates	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	antecedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	immediate reference hold, propose candidate higher score collocational pattern.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	indicator hold again, go recent candidate.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	3.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Evaluation.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evaluation, however, suggests much less lost might feared.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	resolution anaphors carried suc­ cess rate 95.8%.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Example: Identify draweq lit paper port LED add paper itj.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evaluation indicated 83.6% success rate.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evaluation estab­ lished critical success rate 82%.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	7 % 31.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	expected, frequent indica­ tors discriminative ones.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	3.3 Comparison similar approaches: compara­.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	CogNIAC successfully resolved pronouns 75% cases.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	result comparable results described (Baldwin 1997).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	"languages attractive feature NLP approach would language ""universality""."	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	time being, using scores Polish.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	preference-based approach showed clear su­ periority baseline models.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	1
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Our paper discusses a particular configuration of this new evaluation environment incorporating three approaches sharing a common â€knowledge-poor philosophyâ€: Kennedy and Boguraevâ€™s (1996) parser-free algorithm, Baldwinâ€™s (1997) CogNiac and Mitkovâ€™s (1998b) knowledge-poor approach.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Robust pronoun resolution limited knowledge	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Input checked agreement number antecedent indicators.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	immediate reference identified, priority given candi date best collocation pattern score.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	help, candidate higher score indicating verbs preferred.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	2.1 Antecedent indicators.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	following shall outline indicators used shall illustrate ex­ amples.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	new information, rheme, provides information theme.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	preference explained terms sali­ ence point view centering theory.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Example: Press keyi turn volume up...	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Press iti again.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	preference viewed modification collocation preference.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	also quite fre­ quent imperative constructions.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Example: print paper, stand printeri lay iti flat.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	turn printer, press Power buttoni hold iti moment.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Unwrap paperi• form iti align iti• load iti drawer.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	21dentification clauses complex sentences e heuristically.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	scores determined experimentally empirical basis constantly up­ dated.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	point antecedent indicators preferences absolute factors.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	2.2 Informal description algorithm.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Examine current sentence two pre­.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	ceding sentences (if available).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Look noun phrases3 left anaphor4 2.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Select noun phrases identified only.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	agree gender numberS pronominal anaphor group set potential candidates	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	antecedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	immediate reference hold, propose candidate higher score collocational pattern.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	indicator hold again, go recent candidate.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	3.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Evaluation.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evaluation, however, suggests much less lost might feared.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	resolution anaphors carried suc­ cess rate 95.8%.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Example: Identify draweq lit paper port LED add paper itj.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evaluation indicated 83.6% success rate.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evaluation estab­ lished critical success rate 82%.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	7 % 31.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	expected, frequent indica­ tors discriminative ones.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	3.3 Comparison similar approaches: compara­.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	CogNIAC successfully resolved pronouns 75% cases.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	result comparable results described (Baldwin 1997).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	"languages attractive feature NLP approach would language ""universality""."	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	time being, using scores Polish.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	preference-based approach showed clear su­ periority baseline models.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Mitkovâ€™s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Robust pronoun resolution limited knowledge	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Input checked agreement number antecedent indicators.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	immediate reference identified, priority given candi date best collocation pattern score.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	help, candidate higher score indicating verbs preferred.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	still choice possible, recent remaining candi­ dates selected antecedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	2.1 Antecedent indicators.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	following shall outline indicators used shall illustrate ex­ amples.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	new information, rheme, provides information theme.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	preference explained terms sali­ ence point view centering theory.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Example: Press keyi turn volume up...	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Press iti again.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	preference viewed modification collocation preference.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	also quite fre­ quent imperative constructions.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Example: print paper, stand printeri lay iti flat.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	turn printer, press Power buttoni hold iti moment.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Unwrap paperi• form iti align iti• load iti drawer.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	21dentification clauses complex sentences e heuristically.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	scores determined experimentally empirical basis constantly up­ dated.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	point antecedent indicators preferences absolute factors.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"might cases one antecedent indicators ""point"" correct antecedent."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	2.2 Informal description algorithm.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Examine current sentence two pre­.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	ceding sentences (if available).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Look noun phrases3 left anaphor4 2.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Select noun phrases identified only.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	agree gender numberS pronominal anaphor group set potential candidates	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	antecedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	immediate reference hold, propose candidate higher score collocational pattern.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	indicator hold again, go recent candidate.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	3.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Evaluation.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evaluation, however, suggests much less lost might feared.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	resolution anaphors carried suc­ cess rate 95.8%.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Example: Identify draweq lit paper port LED add paper itj.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evaluation indicated 83.6% success rate.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evaluation estab­ lished critical success rate 82%.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	7 % 31.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	expected, frequent indica­ tors discriminative ones.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	3.3 Comparison similar approaches: compara­.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	CogNIAC successfully resolved pronouns 75% cases.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	result comparable results described (Baldwin 1997).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	"languages attractive feature NLP approach would language ""universality""."	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	time being, using scores Polish.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	preference-based approach showed clear su­ periority baseline models.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The coreferential chain length of a candidate, or its variants such as occurrence frequency and TFIDF, has been used as a salience factor in some learning-based reference resolution systems (Iida et al., 2003; Mitkov, 1998; Paul et al., 1999; Strube and Muller, 2003).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Robust pronoun resolution limited knowledge	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Input checked agreement number antecedent indicators.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	immediate reference identified, priority given candi date best collocation pattern score.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	help, candidate higher score indicating verbs preferred.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	still choice possible, recent remaining candi­ dates selected antecedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	2.1 Antecedent indicators.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	following shall outline indicators used shall illustrate ex­ amples.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	new information, rheme, provides information theme.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	preference explained terms sali­ ence point view centering theory.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Example: Press keyi turn volume up...	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Press iti again.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	preference viewed modification collocation preference.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	also quite fre­ quent imperative constructions.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Example: print paper, stand printeri lay iti flat.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	turn printer, press Power buttoni hold iti moment.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Unwrap paperi• form iti align iti• load iti drawer.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	21dentification clauses complex sentences e heuristically.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	scores determined experimentally empirical basis constantly up­ dated.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	point antecedent indicators preferences absolute factors.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"might cases one antecedent indicators ""point"" correct antecedent."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	2.2 Informal description algorithm.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Examine current sentence two pre­.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	ceding sentences (if available).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Look noun phrases3 left anaphor4 2.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Select noun phrases identified only.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	agree gender numberS pronominal anaphor group set potential candidates	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	antecedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	immediate reference hold, propose candidate higher score collocational pattern.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	indicator hold again, go recent candidate.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	3.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Evaluation.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evaluation, however, suggests much less lost might feared.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	resolution anaphors carried suc­ cess rate 95.8%.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Example: Identify draweq lit paper port LED add paper itj.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evaluation indicated 83.6% success rate.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evaluation estab­ lished critical success rate 82%.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	7 % 31.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	expected, frequent indica­ tors discriminative ones.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	3.3 Comparison similar approaches: compara­.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	CogNIAC successfully resolved pronouns 75% cases.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	result comparable results described (Baldwin 1997).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	"languages attractive feature NLP approach would language ""universality""."	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	time being, using scores Polish.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	preference-based approach showed clear su­ periority baseline models.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Early work of anaphora resolution focuses on find ing antecedents of pronouns (Hobbs, 1976; Ge et al., 1998; Mitkov, 1998)	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Robust pronoun resolution limited knowledge	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Input checked agreement number antecedent indicators.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	1
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	immediate reference identified, priority given candi date best collocation pattern score.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	help, candidate higher score indicating verbs preferred.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	2.1 Antecedent indicators.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	following shall outline indicators used shall illustrate ex­ amples.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	new information, rheme, provides information theme.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	preference explained terms sali­ ence point view centering theory.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Example: Press keyi turn volume up...	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Press iti again.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	preference viewed modification collocation preference.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	also quite fre­ quent imperative constructions.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Example: print paper, stand printeri lay iti flat.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	turn printer, press Power buttoni hold iti moment.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Unwrap paperi• form iti align iti• load iti drawer.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	21dentification clauses complex sentences e heuristically.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	scores determined experimentally empirical basis constantly up­ dated.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	point antecedent indicators preferences absolute factors.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	2.2 Informal description algorithm.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Examine current sentence two pre­.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	ceding sentences (if available).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Look noun phrases3 left anaphor4 2.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Select noun phrases identified only.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	agree gender numberS pronominal anaphor group set potential candidates	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	antecedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	immediate reference hold, propose candidate higher score collocational pattern.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	indicator hold again, go recent candidate.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	3.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Evaluation.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evaluation, however, suggests much less lost might feared.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	resolution anaphors carried suc­ cess rate 95.8%.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Example: Identify draweq lit paper port LED add paper itj.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evaluation indicated 83.6% success rate.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evaluation estab­ lished critical success rate 82%.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	7 % 31.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	expected, frequent indica­ tors discriminative ones.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	3.3 Comparison similar approaches: compara­.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	CogNIAC successfully resolved pronouns 75% cases.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	result comparable results described (Baldwin 1997).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	"languages attractive feature NLP approach would language ""universality""."	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	time being, using scores Polish.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	preference-based approach showed clear su­ periority baseline models.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Indeed, existing learning-based approaches to anaphor resolution have performed reasonably well using limited and shallow knowledge (e.g., Mitkov (1998), Soon et al.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	2.1 Antecedent indicators.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	new information, rheme, provides information theme.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Example: Press keyi turn volume up...	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Press iti again.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	preference viewed modification collocation preference.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	2.2 Informal description algorithm.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Examine current sentence two pre­.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	ceding sentences (if available).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Select noun phrases identified only.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	antecedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	indicator hold again, go recent candidate.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	3.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Evaluation.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	7 % 31.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	time being, using scores Polish.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
ParalStuctmarks whether a candidate and an anaphor have sim StatSemN (C, ana) = c max StatSem(ci , ana) (ana) ilar surrounding words, which is also a salience factor for the candidate evaluation (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Robust pronoun resolution limited knowledge	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Input checked agreement number antecedent indicators.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	immediate reference identified, priority given candi date best collocation pattern score.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	help, candidate higher score indicating verbs preferred.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	still choice possible, recent remaining candi­ dates selected antecedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	2.1 Antecedent indicators.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	following shall outline indicators used shall illustrate ex­ amples.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	new information, rheme, provides information theme.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	preference explained terms sali­ ence point view centering theory.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Example: Press keyi turn volume up...	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Press iti again.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	preference viewed modification collocation preference.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	also quite fre­ quent imperative constructions.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Example: print paper, stand printeri lay iti flat.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	turn printer, press Power buttoni hold iti moment.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Unwrap paperi• form iti align iti• load iti drawer.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	21dentification clauses complex sentences e heuristically.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	scores determined experimentally empirical basis constantly up­ dated.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	point antecedent indicators preferences absolute factors.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"might cases one antecedent indicators ""point"" correct antecedent."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	2.2 Informal description algorithm.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Examine current sentence two pre­.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	ceding sentences (if available).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Look noun phrases3 left anaphor4 2.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Select noun phrases identified only.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	agree gender numberS pronominal anaphor group set potential candidates	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	antecedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	immediate reference hold, propose candidate higher score collocational pattern.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	indicator hold again, go recent candidate.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	3.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Evaluation.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evaluation, however, suggests much less lost might feared.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	resolution anaphors carried suc­ cess rate 95.8%.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Example: Identify draweq lit paper port LED add paper itj.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evaluation indicated 83.6% success rate.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evaluation estab­ lished critical success rate 82%.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	7 % 31.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	expected, frequent indica­ tors discriminative ones.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	3.3 Comparison similar approaches: compara­.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	CogNIAC successfully resolved pronouns 75% cases.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	result comparable results described (Baldwin 1997).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	"languages attractive feature NLP approach would language ""universality""."	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	time being, using scores Polish.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	preference-based approach showed clear su­ periority baseline models.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Robust pronoun resolution limited knowledge	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Input checked agreement number antecedent indicators.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	immediate reference identified, priority given candi date best collocation pattern score.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	help, candidate higher score indicating verbs preferred.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	2.1 Antecedent indicators.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	following shall outline indicators used shall illustrate ex­ amples.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	new information, rheme, provides information theme.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	preference explained terms sali­ ence point view centering theory.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Example: Press keyi turn volume up...	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Press iti again.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	preference viewed modification collocation preference.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	also quite fre­ quent imperative constructions.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Example: print paper, stand printeri lay iti flat.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	turn printer, press Power buttoni hold iti moment.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Unwrap paperi• form iti align iti• load iti drawer.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	21dentification clauses complex sentences e heuristically.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	scores determined experimentally empirical basis constantly up­ dated.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	point antecedent indicators preferences absolute factors.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	2.2 Informal description algorithm.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Examine current sentence two pre­.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	ceding sentences (if available).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Look noun phrases3 left anaphor4 2.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Select noun phrases identified only.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	agree gender numberS pronominal anaphor group set potential candidates	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	antecedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	immediate reference hold, propose candidate higher score collocational pattern.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	indicator hold again, go recent candidate.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	3.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Evaluation.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evaluation, however, suggests much less lost might feared.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	resolution anaphors carried suc­ cess rate 95.8%.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Example: Identify draweq lit paper port LED add paper itj.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evaluation indicated 83.6% success rate.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evaluation estab­ lished critical success rate 82%.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	7 % 31.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	expected, frequent indica­ tors discriminative ones.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	3.3 Comparison similar approaches: compara­.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	CogNIAC successfully resolved pronouns 75% cases.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	result comparable results described (Baldwin 1997).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	"languages attractive feature NLP approach would language ""universality""."	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	time being, using scores Polish.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	preference-based approach showed clear su­ periority baseline models.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., Mitkov (1998), Tetreault (2001)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Robust pronoun resolution limited knowledge	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Input checked agreement number antecedent indicators.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	immediate reference identified, priority given candi date best collocation pattern score.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	help, candidate higher score indicating verbs preferred.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	still choice possible, recent remaining candi­ dates selected antecedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	2.1 Antecedent indicators.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	following shall outline indicators used shall illustrate ex­ amples.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	new information, rheme, provides information theme.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	preference explained terms sali­ ence point view centering theory.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Example: Press keyi turn volume up...	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Press iti again.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	preference viewed modification collocation preference.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	also quite fre­ quent imperative constructions.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Example: print paper, stand printeri lay iti flat.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	turn printer, press Power buttoni hold iti moment.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Unwrap paperi• form iti align iti• load iti drawer.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	21dentification clauses complex sentences e heuristically.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	scores determined experimentally empirical basis constantly up­ dated.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	point antecedent indicators preferences absolute factors.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"might cases one antecedent indicators ""point"" correct antecedent."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	2.2 Informal description algorithm.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Examine current sentence two pre­.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	ceding sentences (if available).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Look noun phrases3 left anaphor4 2.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Select noun phrases identified only.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	agree gender numberS pronominal anaphor group set potential candidates	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	antecedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	immediate reference hold, propose candidate higher score collocational pattern.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	indicator hold again, go recent candidate.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	3.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Evaluation.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evaluation, however, suggests much less lost might feared.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	resolution anaphors carried suc­ cess rate 95.8%.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Example: Identify draweq lit paper port LED add paper itj.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evaluation indicated 83.6% success rate.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evaluation estab­ lished critical success rate 82%.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	7 % 31.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	expected, frequent indica­ tors discriminative ones.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	3.3 Comparison similar approaches: compara­.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	CogNIAC successfully resolved pronouns 75% cases.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	result comparable results described (Baldwin 1997).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	"languages attractive feature NLP approach would language ""universality""."	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	time being, using scores Polish.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	preference-based approach showed clear su­ periority baseline models.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The algorithm with the next-to-highest results in (Char- niak and Elsner, 2009) is MARS (Mitkov, 1998) from the GuiTAR (Poesio and Kabadjov, 2004) toolkit.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Robust pronoun resolution limited knowledge	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Input checked agreement number antecedent indicators.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	immediate reference identified, priority given candi date best collocation pattern score.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	help, candidate higher score indicating verbs preferred.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	still choice possible, recent remaining candi­ dates selected antecedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	2.1 Antecedent indicators.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	following shall outline indicators used shall illustrate ex­ amples.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	new information, rheme, provides information theme.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	preference explained terms sali­ ence point view centering theory.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Example: Press keyi turn volume up...	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Press iti again.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	preference viewed modification collocation preference.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	also quite fre­ quent imperative constructions.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Example: print paper, stand printeri lay iti flat.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	turn printer, press Power buttoni hold iti moment.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Unwrap paperi• form iti align iti• load iti drawer.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	21dentification clauses complex sentences e heuristically.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	scores determined experimentally empirical basis constantly up­ dated.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	point antecedent indicators preferences absolute factors.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"might cases one antecedent indicators ""point"" correct antecedent."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	2.2 Informal description algorithm.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Examine current sentence two pre­.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	ceding sentences (if available).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Look noun phrases3 left anaphor4 2.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Select noun phrases identified only.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	agree gender numberS pronominal anaphor group set potential candidates	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	antecedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	immediate reference hold, propose candidate higher score collocational pattern.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	indicator hold again, go recent candidate.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	3.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Evaluation.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evaluation, however, suggests much less lost might feared.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	resolution anaphors carried suc­ cess rate 95.8%.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Example: Identify draweq lit paper port LED add paper itj.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evaluation indicated 83.6% success rate.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evaluation estab­ lished critical success rate 82%.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	7 % 31.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	expected, frequent indica­ tors discriminative ones.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	3.3 Comparison similar approaches: compara­.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	CogNIAC successfully resolved pronouns 75% cases.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	result comparable results described (Baldwin 1997).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	"languages attractive feature NLP approach would language ""universality""."	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	time being, using scores Polish.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	preference-based approach showed clear su­ periority baseline models.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Robust pronoun resolution limited knowledge	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Input checked agreement number antecedent indicators.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	immediate reference identified, priority given candi date best collocation pattern score.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	help, candidate higher score indicating verbs preferred.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	2.1 Antecedent indicators.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	following shall outline indicators used shall illustrate ex­ amples.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	new information, rheme, provides information theme.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	preference explained terms sali­ ence point view centering theory.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Example: Press keyi turn volume up...	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Press iti again.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	preference viewed modification collocation preference.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	also quite fre­ quent imperative constructions.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Example: print paper, stand printeri lay iti flat.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	turn printer, press Power buttoni hold iti moment.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Unwrap paperi• form iti align iti• load iti drawer.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	21dentification clauses complex sentences e heuristically.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	scores determined experimentally empirical basis constantly up­ dated.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	point antecedent indicators preferences absolute factors.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	2.2 Informal description algorithm.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Examine current sentence two pre­.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	ceding sentences (if available).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Look noun phrases3 left anaphor4 2.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Select noun phrases identified only.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	agree gender numberS pronominal anaphor group set potential candidates	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	antecedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	immediate reference hold, propose candidate higher score collocational pattern.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	indicator hold again, go recent candidate.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	3.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Evaluation.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evaluation, however, suggests much less lost might feared.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	resolution anaphors carried suc­ cess rate 95.8%.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Example: Identify draweq lit paper port LED add paper itj.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evaluation indicated 83.6% success rate.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evaluation estab­ lished critical success rate 82%.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	7 % 31.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	expected, frequent indica­ tors discriminative ones.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	3.3 Comparison similar approaches: compara­.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	CogNIAC successfully resolved pronouns 75% cases.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	result comparable results described (Baldwin 1997).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	"languages attractive feature NLP approach would language ""universality""."	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	time being, using scores Polish.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	preference-based approach showed clear su­ periority baseline models.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Coreference resolution is a field in which major progress has been made in the last decade.  After a concentration on rule-based systems (cf.  e.g.  (Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Robust pronoun resolution limited knowledge	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Input checked agreement number antecedent indicators.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	immediate reference identified, priority given candi date best collocation pattern score.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	help, candidate higher score indicating verbs preferred.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	still choice possible, recent remaining candi­ dates selected antecedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	2.1 Antecedent indicators.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	following shall outline indicators used shall illustrate ex­ amples.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	new information, rheme, provides information theme.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	preference explained terms sali­ ence point view centering theory.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Example: Press keyi turn volume up...	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Press iti again.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	preference viewed modification collocation preference.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	also quite fre­ quent imperative constructions.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Example: print paper, stand printeri lay iti flat.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	turn printer, press Power buttoni hold iti moment.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Unwrap paperi• form iti align iti• load iti drawer.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	21dentification clauses complex sentences e heuristically.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	scores determined experimentally empirical basis constantly up­ dated.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	point antecedent indicators preferences absolute factors.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"might cases one antecedent indicators ""point"" correct antecedent."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	2.2 Informal description algorithm.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Examine current sentence two pre­.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	ceding sentences (if available).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Look noun phrases3 left anaphor4 2.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Select noun phrases identified only.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	agree gender numberS pronominal anaphor group set potential candidates	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	antecedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	immediate reference hold, propose candidate higher score collocational pattern.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	indicator hold again, go recent candidate.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	3.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Evaluation.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evaluation, however, suggests much less lost might feared.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	resolution anaphors carried suc­ cess rate 95.8%.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Example: Identify draweq lit paper port LED add paper itj.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evaluation indicated 83.6% success rate.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evaluation estab­ lished critical success rate 82%.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	7 % 31.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	expected, frequent indica­ tors discriminative ones.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	3.3 Comparison similar approaches: compara­.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	CogNIAC successfully resolved pronouns 75% cases.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	result comparable results described (Baldwin 1997).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	"languages attractive feature NLP approach would language ""universality""."	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	time being, using scores Polish.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	preference-based approach showed clear su­ periority baseline models.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
They use limited knowledge (lexical, morphological and syntacticinformation sources) for the detection of the cor rect antecedent.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Robust pronoun resolution limited knowledge	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Input checked agreement number antecedent indicators.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	immediate reference identified, priority given candi date best collocation pattern score.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	help, candidate higher score indicating verbs preferred.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	still choice possible, recent remaining candi­ dates selected antecedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	2.1 Antecedent indicators.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	following shall outline indicators used shall illustrate ex­ amples.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	new information, rheme, provides information theme.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	preference explained terms sali­ ence point view centering theory.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Example: Press keyi turn volume up...	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Press iti again.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	preference viewed modification collocation preference.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	also quite fre­ quent imperative constructions.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Example: print paper, stand printeri lay iti flat.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	turn printer, press Power buttoni hold iti moment.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Unwrap paperi• form iti align iti• load iti drawer.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	21dentification clauses complex sentences e heuristically.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	scores determined experimentally empirical basis constantly up­ dated.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	point antecedent indicators preferences absolute factors.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"might cases one antecedent indicators ""point"" correct antecedent."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	2.2 Informal description algorithm.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Examine current sentence two pre­.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	ceding sentences (if available).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Look noun phrases3 left anaphor4 2.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Select noun phrases identified only.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	agree gender numberS pronominal anaphor group set potential candidates	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	antecedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	immediate reference hold, propose candidate higher score collocational pattern.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	indicator hold again, go recent candidate.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	3.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Evaluation.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evaluation, however, suggests much less lost might feared.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	resolution anaphors carried suc­ cess rate 95.8%.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Example: Identify draweq lit paper port LED add paper itj.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evaluation indicated 83.6% success rate.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evaluation estab­ lished critical success rate 82%.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	7 % 31.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	expected, frequent indica­ tors discriminative ones.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	3.3 Comparison similar approaches: compara­.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	CogNIAC successfully resolved pronouns 75% cases.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	result comparable results described (Baldwin 1997).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	"languages attractive feature NLP approach would language ""universality""."	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	time being, using scores Polish.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	preference-based approach showed clear su­ periority baseline models.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; Mitkov, 1998b; Mitkov, 1999).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	2.1 Antecedent indicators.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	new information, rheme, provides information theme.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Example: Press keyi turn volume up...	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Press iti again.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	preference viewed modification collocation preference.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	2.2 Informal description algorithm.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Examine current sentence two pre­.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	ceding sentences (if available).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Select noun phrases identified only.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	antecedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	indicator hold again, go recent candidate.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	3.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Evaluation.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	7 % 31.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	time being, using scores Polish.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkovâ€™s algorithm for pronoun resolution (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Robust pronoun resolution limited knowledge	1
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Input checked agreement number antecedent indicators.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	immediate reference identified, priority given candi date best collocation pattern score.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	help, candidate higher score indicating verbs preferred.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	still choice possible, recent remaining candi­ dates selected antecedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	2.1 Antecedent indicators.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	following shall outline indicators used shall illustrate ex­ amples.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	new information, rheme, provides information theme.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	preference explained terms sali­ ence point view centering theory.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Example: Press keyi turn volume up...	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Press iti again.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	preference viewed modification collocation preference.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	also quite fre­ quent imperative constructions.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Example: print paper, stand printeri lay iti flat.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	turn printer, press Power buttoni hold iti moment.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Unwrap paperi• form iti align iti• load iti drawer.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	21dentification clauses complex sentences e heuristically.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	scores determined experimentally empirical basis constantly up­ dated.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	point antecedent indicators preferences absolute factors.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"might cases one antecedent indicators ""point"" correct antecedent."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	2.2 Informal description algorithm.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Examine current sentence two pre­.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	ceding sentences (if available).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Look noun phrases3 left anaphor4 2.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Select noun phrases identified only.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	agree gender numberS pronominal anaphor group set potential candidates	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	antecedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	immediate reference hold, propose candidate higher score collocational pattern.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	indicator hold again, go recent candidate.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	3.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Evaluation.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evaluation, however, suggests much less lost might feared.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	resolution anaphors carried suc­ cess rate 95.8%.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Example: Identify draweq lit paper port LED add paper itj.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evaluation indicated 83.6% success rate.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evaluation estab­ lished critical success rate 82%.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	7 % 31.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	expected, frequent indica­ tors discriminative ones.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	3.3 Comparison similar approaches: compara­.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	CogNIAC successfully resolved pronouns 75% cases.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	result comparable results described (Baldwin 1997).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	"languages attractive feature NLP approach would language ""universality""."	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	time being, using scores Polish.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	preference-based approach showed clear su­ periority baseline models.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
(PMID:9701290) Table 1: A protein domain-referring phrase example ments and lexical features, in addressing problems in the biomedical domain (cf.  Mitkov et al.  (1998)).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Robust pronoun resolution limited knowledge	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Input checked agreement number antecedent indicators.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	immediate reference identified, priority given candi date best collocation pattern score.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	help, candidate higher score indicating verbs preferred.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	2.1 Antecedent indicators.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	following shall outline indicators used shall illustrate ex­ amples.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	new information, rheme, provides information theme.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	preference explained terms sali­ ence point view centering theory.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Example: Press keyi turn volume up...	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Press iti again.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	preference viewed modification collocation preference.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	also quite fre­ quent imperative constructions.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Example: print paper, stand printeri lay iti flat.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	turn printer, press Power buttoni hold iti moment.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Unwrap paperi• form iti align iti• load iti drawer.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	21dentification clauses complex sentences e heuristically.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	scores determined experimentally empirical basis constantly up­ dated.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	point antecedent indicators preferences absolute factors.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	2.2 Informal description algorithm.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Examine current sentence two pre­.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	ceding sentences (if available).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Look noun phrases3 left anaphor4 2.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Select noun phrases identified only.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	agree gender numberS pronominal anaphor group set potential candidates	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	antecedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	immediate reference hold, propose candidate higher score collocational pattern.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	indicator hold again, go recent candidate.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	3.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Evaluation.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evaluation, however, suggests much less lost might feared.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	resolution anaphors carried suc­ cess rate 95.8%.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Example: Identify draweq lit paper port LED add paper itj.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evaluation indicated 83.6% success rate.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evaluation estab­ lished critical success rate 82%.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	7 % 31.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	expected, frequent indica­ tors discriminative ones.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	3.3 Comparison similar approaches: compara­.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	CogNIAC successfully resolved pronouns 75% cases.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	result comparable results described (Baldwin 1997).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	"languages attractive feature NLP approach would language ""universality""."	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	time being, using scores Polish.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	preference-based approach showed clear su­ periority baseline models.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; FerrÃ¡ndez et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Robust pronoun resolution limited knowledge	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Input checked agreement number antecedent indicators.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	immediate reference identified, priority given candi date best collocation pattern score.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	help, candidate higher score indicating verbs preferred.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	still choice possible, recent remaining candi­ dates selected antecedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	2.1 Antecedent indicators.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	following shall outline indicators used shall illustrate ex­ amples.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	new information, rheme, provides information theme.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	preference explained terms sali­ ence point view centering theory.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Example: Press keyi turn volume up...	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Press iti again.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	preference viewed modification collocation preference.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	also quite fre­ quent imperative constructions.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Example: print paper, stand printeri lay iti flat.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	turn printer, press Power buttoni hold iti moment.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Unwrap paperi• form iti align iti• load iti drawer.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	21dentification clauses complex sentences e heuristically.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	scores determined experimentally empirical basis constantly up­ dated.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	point antecedent indicators preferences absolute factors.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"might cases one antecedent indicators ""point"" correct antecedent."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	2.2 Informal description algorithm.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Examine current sentence two pre­.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	ceding sentences (if available).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Look noun phrases3 left anaphor4 2.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Select noun phrases identified only.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	agree gender numberS pronominal anaphor group set potential candidates	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	antecedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	immediate reference hold, propose candidate higher score collocational pattern.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	indicator hold again, go recent candidate.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	3.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Evaluation.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evaluation, however, suggests much less lost might feared.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	resolution anaphors carried suc­ cess rate 95.8%.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Example: Identify draweq lit paper port LED add paper itj.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evaluation indicated 83.6% success rate.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evaluation estab­ lished critical success rate 82%.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	7 % 31.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	expected, frequent indica­ tors discriminative ones.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	3.3 Comparison similar approaches: compara­.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	CogNIAC successfully resolved pronouns 75% cases.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	result comparable results described (Baldwin 1997).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	"languages attractive feature NLP approach would language ""universality""."	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	time being, using scores Polish.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	preference-based approach showed clear su­ periority baseline models.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
In most systems ((Mitkov, 1998),(Lappin and Leass, 1994)) the weights that are assigned for different anaphor-antecedent relationships are programmer dependent.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Robust pronoun resolution limited knowledge	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Input checked agreement number antecedent indicators.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	immediate reference identified, priority given candi date best collocation pattern score.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	help, candidate higher score indicating verbs preferred.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	still choice possible, recent remaining candi­ dates selected antecedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	2.1 Antecedent indicators.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	following shall outline indicators used shall illustrate ex­ amples.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	new information, rheme, provides information theme.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	preference explained terms sali­ ence point view centering theory.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Example: Press keyi turn volume up...	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Press iti again.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	preference viewed modification collocation preference.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	also quite fre­ quent imperative constructions.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Example: print paper, stand printeri lay iti flat.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	turn printer, press Power buttoni hold iti moment.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Unwrap paperi• form iti align iti• load iti drawer.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	21dentification clauses complex sentences e heuristically.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	scores determined experimentally empirical basis constantly up­ dated.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	point antecedent indicators preferences absolute factors.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"might cases one antecedent indicators ""point"" correct antecedent."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	2.2 Informal description algorithm.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Examine current sentence two pre­.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	ceding sentences (if available).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Look noun phrases3 left anaphor4 2.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Select noun phrases identified only.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	agree gender numberS pronominal anaphor group set potential candidates	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	antecedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	immediate reference hold, propose candidate higher score collocational pattern.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	indicator hold again, go recent candidate.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	3.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Evaluation.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evaluation, however, suggests much less lost might feared.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	resolution anaphors carried suc­ cess rate 95.8%.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Example: Identify draweq lit paper port LED add paper itj.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evaluation indicated 83.6% success rate.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evaluation estab­ lished critical success rate 82%.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	7 % 31.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	expected, frequent indica­ tors discriminative ones.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	3.3 Comparison similar approaches: compara­.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	CogNIAC successfully resolved pronouns 75% cases.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	result comparable results described (Baldwin 1997).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	"languages attractive feature NLP approach would language ""universality""."	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	time being, using scores Polish.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	preference-based approach showed clear su­ periority baseline models.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Often domain-specific heuristics are used for anaphora resolution and fine tuned to perform well on a limited corpus, such as in (Mitkov, 1998).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Robust pronoun resolution limited knowledge	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Input checked agreement number antecedent indicators.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	immediate reference identified, priority given candi date best collocation pattern score.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	help, candidate higher score indicating verbs preferred.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	still choice possible, recent remaining candi­ dates selected antecedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	2.1 Antecedent indicators.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	following shall outline indicators used shall illustrate ex­ amples.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	new information, rheme, provides information theme.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	preference explained terms sali­ ence point view centering theory.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Example: Press keyi turn volume up...	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Press iti again.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	preference viewed modification collocation preference.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	also quite fre­ quent imperative constructions.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Example: print paper, stand printeri lay iti flat.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	turn printer, press Power buttoni hold iti moment.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Unwrap paperi• form iti align iti• load iti drawer.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	21dentification clauses complex sentences e heuristically.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	scores determined experimentally empirical basis constantly up­ dated.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	point antecedent indicators preferences absolute factors.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"might cases one antecedent indicators ""point"" correct antecedent."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	2.2 Informal description algorithm.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Examine current sentence two pre­.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	ceding sentences (if available).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Look noun phrases3 left anaphor4 2.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Select noun phrases identified only.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	agree gender numberS pronominal anaphor group set potential candidates	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	antecedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	immediate reference hold, propose candidate higher score collocational pattern.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	indicator hold again, go recent candidate.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	3.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Evaluation.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evaluation, however, suggests much less lost might feared.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	resolution anaphors carried suc­ cess rate 95.8%.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Example: Identify draweq lit paper port LED add paper itj.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evaluation indicated 83.6% success rate.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evaluation estab­ lished critical success rate 82%.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	7 % 31.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	expected, frequent indica­ tors discriminative ones.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	3.3 Comparison similar approaches: compara­.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	CogNIAC successfully resolved pronouns 75% cases.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	result comparable results described (Baldwin 1997).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	"languages attractive feature NLP approach would language ""universality""."	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	time being, using scores Polish.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	preference-based approach showed clear su­ periority baseline models.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The approach is presented as a knowledge poor anaphora resolution algorithm (Mitkov R. [1995;1998]), which makes use of POS and NP chunking, it tries to individuate pleonastic â€œitâ€ occurrences, and assigns animacy.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Robust pronoun resolution limited knowledge	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Input checked agreement number antecedent indicators.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	immediate reference identified, priority given candi date best collocation pattern score.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	help, candidate higher score indicating verbs preferred.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	2.1 Antecedent indicators.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	following shall outline indicators used shall illustrate ex­ amples.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	new information, rheme, provides information theme.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	preference explained terms sali­ ence point view centering theory.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Example: Press keyi turn volume up...	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Press iti again.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	preference viewed modification collocation preference.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	also quite fre­ quent imperative constructions.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Example: print paper, stand printeri lay iti flat.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	turn printer, press Power buttoni hold iti moment.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Unwrap paperi• form iti align iti• load iti drawer.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	21dentification clauses complex sentences e heuristically.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	scores determined experimentally empirical basis constantly up­ dated.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	point antecedent indicators preferences absolute factors.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	2.2 Informal description algorithm.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Examine current sentence two pre­.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	ceding sentences (if available).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Look noun phrases3 left anaphor4 2.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Select noun phrases identified only.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	agree gender numberS pronominal anaphor group set potential candidates	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	antecedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	immediate reference hold, propose candidate higher score collocational pattern.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	indicator hold again, go recent candidate.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	3.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Evaluation.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evaluation, however, suggests much less lost might feared.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	resolution anaphors carried suc­ cess rate 95.8%.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Example: Identify draweq lit paper port LED add paper itj.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evaluation indicated 83.6% success rate.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evaluation estab­ lished critical success rate 82%.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	7 % 31.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	expected, frequent indica­ tors discriminative ones.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	3.3 Comparison similar approaches: compara­.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	CogNIAC successfully resolved pronouns 75% cases.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	result comparable results described (Baldwin 1997).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	"languages attractive feature NLP approach would language ""universality""."	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	time being, using scores Polish.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	preference-based approach showed clear su­ periority baseline models.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Some of the limitations of the traditional rule based approaches (Mitkov, 1998) could be overcome by machine learning techniques, which allow automating the acquisition of knowledge from annotated corpora.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Robust pronoun resolution limited knowledge	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Input checked agreement number antecedent indicators.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	immediate reference identified, priority given candi date best collocation pattern score.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	help, candidate higher score indicating verbs preferred.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	2.1 Antecedent indicators.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	following shall outline indicators used shall illustrate ex­ amples.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	new information, rheme, provides information theme.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	preference explained terms sali­ ence point view centering theory.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Example: Press keyi turn volume up...	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Press iti again.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	preference viewed modification collocation preference.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	also quite fre­ quent imperative constructions.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Example: print paper, stand printeri lay iti flat.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	turn printer, press Power buttoni hold iti moment.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Unwrap paperi• form iti align iti• load iti drawer.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	21dentification clauses complex sentences e heuristically.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	scores determined experimentally empirical basis constantly up­ dated.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	point antecedent indicators preferences absolute factors.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	2.2 Informal description algorithm.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Examine current sentence two pre­.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	ceding sentences (if available).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Look noun phrases3 left anaphor4 2.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Select noun phrases identified only.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	agree gender numberS pronominal anaphor group set potential candidates	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	antecedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	immediate reference hold, propose candidate higher score collocational pattern.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	indicator hold again, go recent candidate.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	3.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Evaluation.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evaluation, however, suggests much less lost might feared.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	resolution anaphors carried suc­ cess rate 95.8%.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Example: Identify draweq lit paper port LED add paper itj.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evaluation indicated 83.6% success rate.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evaluation estab­ lished critical success rate 82%.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	7 % 31.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	expected, frequent indica­ tors discriminative ones.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	3.3 Comparison similar approaches: compara­.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	CogNIAC successfully resolved pronouns 75% cases.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	result comparable results described (Baldwin 1997).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	"languages attractive feature NLP approach would language ""universality""."	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	time being, using scores Polish.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	preference-based approach showed clear su­ periority baseline models.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Robust pronoun resolution limited knowledge	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Input checked agreement number antecedent indicators.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Candidates assigned scores indicator candidate highest score returned antecedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	immediate reference identified, priority given candi date best collocation pattern score.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	help, candidate higher score indicating verbs preferred.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	still choice possible, recent remaining candi­ dates selected antecedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	2.1 Antecedent indicators.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	following shall outline indicators used shall illustrate ex­ amples.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	new information, rheme, provides information theme.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Example: Insert cassettei VCR making sure iti suitable length recording.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	preference explained terms sali­ ence point view centering theory.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Example: Press keyi turn volume up...	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Press iti again.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	preference viewed modification collocation preference.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	also quite fre­ quent imperative constructions.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Example: print paper, stand printeri lay iti flat.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	turn printer, press Power buttoni hold iti moment.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Unwrap paperi• form iti align iti• load iti drawer.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	21dentification clauses complex sentences e heuristically.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	scores determined experimentally empirical basis constantly up­ dated.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	point antecedent indicators preferences absolute factors.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"might cases one antecedent indicators ""point"" correct antecedent."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	2.2 Informal description algorithm.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	algorithm pronoun resolution de­ scribed informally follows: 1.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Examine current sentence two pre­.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	ceding sentences (if available).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Look noun phrases3 left anaphor4 2.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Select noun phrases identified only.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	agree gender numberS pronominal anaphor group set potential candidates	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	antecedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	immediate reference hold, propose candidate higher score collocational pattern.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	indicator hold again, go recent candidate.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	3.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Evaluation.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evaluation, however, suggests much less lost might feared.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	resolution anaphors carried suc­ cess rate 95.8%.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Example: Identify draweq lit paper port LED add paper itj.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evaluation indicated 83.6% success rate.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evaluation estab­ lished critical success rate 82%.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	7 % 31.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	expected, frequent indica­ tors discriminative ones.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	3.3 Comparison similar approaches: compara­.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	CogNIAC successfully resolved pronouns 75% cases.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	result comparable results described (Baldwin 1997).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	"languages attractive feature NLP approach would language ""universality""."	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	time being, using scores Polish.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	preference-based approach showed clear su­ periority baseline models.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Robust pronoun resolution limited knowledge	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Input checked agreement number antecedent indicators.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	immediate reference identified, priority given candi date best collocation pattern score.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	help, candidate higher score indicating verbs preferred.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	still choice possible, recent remaining candi­ dates selected antecedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	2.1 Antecedent indicators.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	following shall outline indicators used shall illustrate ex­ amples.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	new information, rheme, provides information theme.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	preference explained terms sali­ ence point view centering theory.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Example: Press keyi turn volume up...	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Press iti again.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	preference viewed modification collocation preference.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	also quite fre­ quent imperative constructions.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Example: print paper, stand printeri lay iti flat.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	turn printer, press Power buttoni hold iti moment.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Unwrap paperi• form iti align iti• load iti drawer.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	21dentification clauses complex sentences e heuristically.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	scores determined experimentally empirical basis constantly up­ dated.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	point antecedent indicators preferences absolute factors.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"might cases one antecedent indicators ""point"" correct antecedent."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	2.2 Informal description algorithm.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Examine current sentence two pre­.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	ceding sentences (if available).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Look noun phrases3 left anaphor4 2.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Select noun phrases identified only.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	agree gender numberS pronominal anaphor group set potential candidates	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	antecedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	immediate reference hold, propose candidate higher score collocational pattern.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	indicator hold again, go recent candidate.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	3.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Evaluation.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evaluation, however, suggests much less lost might feared.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	resolution anaphors carried suc­ cess rate 95.8%.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Example: Identify draweq lit paper port LED add paper itj.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evaluation indicated 83.6% success rate.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evaluation estab­ lished critical success rate 82%.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	7 % 31.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	expected, frequent indica­ tors discriminative ones.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	3.3 Comparison similar approaches: compara­.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	CogNIAC successfully resolved pronouns 75% cases.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	result comparable results described (Baldwin 1997).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	"languages attractive feature NLP approach would language ""universality""."	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	time being, using scores Polish.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	preference-based approach showed clear su­ periority baseline models.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
However, the difficulty of our task can be verified according to the baseline experiment results reported in (Mitkov, 1998).  Resolving pro­ nouns in English technical manuals to the most re­ cent candidate achieved a success rate of 62.5%, whereas in our experiments only 43.9% of the most recent candidates are resolved correctly as the an­ tecedent (cf.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Robust pronoun resolution limited knowledge	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	traditional approaches anaphora resolution rely heavily linguistic domain knowledge.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	One disadvantages developing knowledge­ based system, however, labour­ intensive time-consuming task.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	paper pres­ ents robust, knowledge-poor approach resolving pronouns technical manuals, operates texts pre-processed part-of-speech tagger.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Input checked agreement number antecedent indicators.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Candidates assigned scores indicator candidate highest score returned antecedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Evaluation reports success rate 89.7% better suc­ cess rates approaches selected comparison tested data.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	addition, preliminary experiments show approach success­ fully adapted languages minimum modifications.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	part, anaphora resolution focused traditional linguistic methods (Carbonell & Brown 1988; Carter 1987; Hobbs 1978; Ingria & Stallard 1989; Lappin & McCord 1990; Lappin & Leass 1994; Mitkov 1994; Rich & LuperFoy 1988; Sidner 1979; Webber 1979).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	However, represent manipulate various types linguistic domain knowledge involved requires considerable human input computational expense.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	various alternatives proposed, making use e.g. neural networks, situation se­ mantics framework, principles reasoning uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin & Akman 1995), still strong need development robust effective strategies meet demands practical NLP systems, enhance automatic pro­ cessing growing language resources.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Several proposals already addressed anaphora resolution problem deliberately limiting extent rely domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan & ltai 1990; Kennedy & Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	work continuation latest trends search inexpensive, fast reliable procedures anaph­ ora resolution.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	also example anaphors specific genre resolved quite successfully without sophisticated linguistic knowledge even without parsing.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Finally, evaluation shows basic set antecedent tracking indicators work well English, also languages (in case Polish Arabic).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	view avoiding complex syntactic, seman­ tic discourse analysis (which vital real­ world applications), developed robust, knowl­ edge-poor approach pronoun resolution parse analyse input order identify antecedents anaphors.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"makes use part-of-speech tagger, plus simple noun phrase rules (sentence constituents identified level noun phrase most) operates basis antecedent-tracking preferences (referred hereafter ""antecedent indicators"")."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	approach works follows: takes input output text processed part-of-speech tagger, identifies noun phrases precede anaphor within distance 2 sentences, checks gender number agreement anaphor applies genre-specific antecedent indicators re­ maining candidates (see next section).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	noun phrase highest aggregate score proposed antecedent; rare event tie, priority given candidate higher score im­ mediate reference.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	immediate reference identified, priority given candi date best collocation pattern score.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	help, candidate higher score indicating verbs preferred.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	still choice possible, recent remaining candi­ dates selected antecedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	2.1 Antecedent indicators.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Antecedent indicators (preferences) play decisive role tracking antecedent set possible candidates.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Candidates assigned score (-1, 0, 1 2) indicator; candidate highest aggregate score proposed ante­ cedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"antecedent indicators identi­ fied empirically related salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, ""non­ prepositional"" noun phrases), structural matches (collocation, immediate reference), referential distance preference terms."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Whilst indicators genre-specific (term prefer­ ence) others less genre-specific (""immediate reference""), majority appear genre­ independent."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	following shall outline indicators used shall illustrate ex­ amples.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Definiteness Definite noun phrases previous sentences likely antecedents pronominal anaphors indefinite ones (definite noun phrases score 0 indefinite ones penalised -1).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	regard noun phrase definite head noun modified definite article, demonstrative posses­ sive pronouns.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	rule ignored definite articles, possessive demonstrative pro­ nouns paragraph (this exception taken account English user's guides tend omit articles).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Givenness Noun phrases previous sentences representing ""given information"" (theme) 1 deemed good candidates antecedents score (candidates representing theme score 0)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	coherent text (Firbas 1992), given known information, theme, usually appears first, thus forms co­ referential link preceding text.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	new information, rheme, provides information theme.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	1We use simple heuristics given information first noun phrase non-imperative sentence.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Indicating verbs verb member Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, consider first NP following preferred an­ tecedent (scores 1 0).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Empirical evidence sug­ gests salience noun phrases follow them, verbs listed particularly good indicators.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Lexical reiteration Lexically reiterated items likely candidates antecedent (a NP scores 2 repeated within paragraph twice more, 1 repeated 0 not).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Lexically reiterated items include re­ peated synonymous noun phrases may often preceded definite articles demonstratives.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Also, sequence noun phrases head counts lexical reiteration (e.g. ""toner bottle"", ""bottle toner"", ""the bottle"")."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Section heading preference noun phrase occurs heading section, part current sentence, con­ sider preferred candidate (1, 0).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Non-prepositional noun phrases ""pure"", ""non-prepositional"" noun phrase given higher preference noun phrase part prepositional phrase (0, -1 )."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Example: Insert cassettei VCR making sure iti suitable length recording.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"the VCR penalised (-1) part prepositional phrase ""into VCR""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	preference explained terms sali­ ence point view centering theory.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"latter proposes ranking ""subject, direct ob­ ject, indirect object"" (Brennan et al. 1987) noun phrases parts prepositional phrases usually indirect objects."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Collocation pattern preference preference given candidates identical collocation pattern pronoun (2,0).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"collocation preference restricted patterns ""noun phrase (pronoun), verb"" ""verb, noun phrase (pronoun)""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Owing lack syntactic information, preference somewhat weaker collocation preference described (Dagan & ltai 1990).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Example: Press keyi turn volume up...	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Press iti again.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Immediate reference technical manuals ""immediate reference"" clue often useful identifying antecedent."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"heuristics used constructions form ""...(You) V 1 NP ... con (you) V 2 (con (you) V3 it)"", con e {and/or/before/after...}, noun phrase immediately V 1 likely candidate antecedent pronoun ""it"" imme­ diately following V2 therefore given preference (scores 2 0)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	preference viewed modification collocation preference.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	also quite fre­ quent imperative constructions.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Example: print paper, stand printeri lay iti flat.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	turn printer, press Power buttoni hold iti moment.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Unwrap paperi• form iti align iti• load iti drawer.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Referential distance complex sentences, noun phrases previous clause2 best candidate antecedent anaphor subsequent clause, followed noun phrases previous sentence, nouns situated 2 sentences back finally nouns 3 sentences back (2, 1, 0, -1).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	anaphors simple sentences, noun phrases previous sen­ tence best candidate antecedent, followed noun phrases situated 2 sentences back finally nouns 3 sentences back {1, 0, -1).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Term preference NPs representing terms field likely antecedent NPs terms (score 1 NP term 0 not).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	21dentification clauses complex sentences e heuristically.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	already mentioned, antecedent in­ dicators assigns score value {-1, 0, 1, 2}.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	scores determined experimentally empirical basis constantly up­ dated.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Top symptoms like ""lexical reiteration"" as­ sign score ""2"" whereas ""non-prepositional"" noun phrases given negative score ""-1""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	point antecedent indicators preferences absolute factors.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"might cases one antecedent indicators ""point"" correct antecedent."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"in­ stance, sentence ""Insert cassette VCRi making sure iti turned on"", indicator ""non-prepositional noun phrases"" would penalise correct antecedent."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"preferences (antecedent indicators) taken account, however, right antecedent still likely tracked - example, ""non-prepositional noun phrases"" heuristics (penalty) would overturned ""collocational preference"" heuristics."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	2.2 Informal description algorithm.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	algorithm pronoun resolution de­ scribed informally follows: 1.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Examine current sentence two pre­.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	ceding sentences (if available).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Look noun phrases3 left anaphor4 2.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Select noun phrases identified only.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	agree gender numberS pronominal anaphor group set potential candidates	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"tial candidate assign scores; candidate highest aggregate score proposed 3A sentence splitter would already segmented text sentences, POS tagger would already determined parts speech simple phrasal grammar would already detected noun phrases 4In project treat cataphora; non-anaphoric ""it"" occurring constructions ""It important"", ""It necessary"" eliminated ""referential filter"" 5Note restriction may always apply lan­ guages English (e.g. German); hand, certain collective nouns English agree number antecedents (e.g. ""government"", ""team"", ""parliament"" etc. referred ""they""; equally plural nouns (e.g. ""data"") referred ""it"") exempted agree­ ment test."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"purpose drawn compre­ hensive list cases; knowledge, computational treatment pronominal anaphora resolu­ tion addressed problem ""agreement excep­ tions""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	antecedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	two candidates equal score, candidate higher score immediate reference proposed antecedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	immediate reference hold, propose candidate higher score collocational pattern.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	collocational pattern suggests tie hold, select candidate higher score indicating verbs.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	indicator hold again, go recent candidate.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	3.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Evaluation.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	practical reasons, approach presented incorporate syntactic semantic information (other list domain terms) real­ istic expect performance good approach makes use syntactic semantic knowledge terms constraints preferences.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	lack syntactic information, instance, means giving c-cornmand constraints subject preference (or occasions object preference, see Mitkov I995) could used center tracking.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Syntactic parallelism, useful discrimi­ nating identical pronouns basis syntactic function, also forgone.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Lack semantic knowledge rules use verb se­ mantics semantic parallelism.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evaluation, however, suggests much less lost might feared.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	fact, evaluation shows re­ sults comparable syntax-based methods (Lappin & Leass I994).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	believe good success rate due fact number ante­ cedent indicators taken account fac­ tor given absolute preference.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	particular, strategy often override incorrect decisions linked strong centering preference (Mitkov & Belguith I998) syntactic semantic parallelism prefer­ ences (see below).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	3.1 Evaluation A. first evaluation exercise (Mitkov & Stys 1997) based random sample text technical manual English (Minolta 1994).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	71 pronouns 140 page technical manual; 7 pronouns non-anaphoric 16 exophoric.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	resolution anaphors carried suc­ cess rate 95.8%.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"approach robust (an attempt made resolve anaphor pro­ posed antecedent returned), figure represents ""precision"" ""recall"" use MUC terminology."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"avoid terminological confusion, shall therefore use neutral term ""success rate"" discussing evaluation."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	order evaluate effectiveness ap­ proach explore far superior baseline models anaphora resolution, also tested sample text (i) Baseline Model checks agreement number gender and, one candidate remains, picks antece­ dent recent subject matching gender number anaphor (ii) Baseline Model picks antecedent recent noun phrase matches gender number anaphor.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"success rate ""Baseline Subject"" 29.2%, whereas success rate ""Baseline Recent NP"" 62.5%."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Given knowledge­ poor approach basically enhancement baseline model set antecedent indica­ tors, see dramatic improvement performance (95.8%) preferences called upon.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Typically, preference-based model proved superior baseline models antece­ dent neither recent subject recent noun phrase matching anaphor gender number.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Example: Identify draweq lit paper port LED add paper itj.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"aggregate score ""the drawer"" 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score recent matching noun phrase (""the lit paper port LED"") 4 (definiteness 1 + givenness 0 + term preference + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	example also see knowledge-poor approach successfully tackles cases anaphor the· antecedent different syntactic functions also different semantic roles.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Usually knowledge-based ap­ proaches difficulties situation use preferences ""syntactic parallelism"" ""semantic parallelism""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	robust approach use information syntactic structure sentence syn­ tactic function/semantic role individual word.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	far typical failure cases concerned, anticipate knowledge-poor approach difficulties sentences com­ plex syntactic structure.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	surpris ing, given approach rely syntactic knowledge particular, produce parse tree.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Indeed, approach fails sentence: paper key used feed [a blank sheet paper]j copier copy tray without making copy itj.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"blank sheet paper scores 2 op­ posed ""the paper key"" scores 6."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	3.2 Evaluation B. carried second evaluation approach different set sample texts genre technical manuals (47-page Portable Style-Writer User's Guide (Stylewriter 1994).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"223 pro­ nouns text, 167 non-anaphoric (deictic non-anaphoric ""it"")."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evaluation carried manual ensure added error gen­ erated (e.g. due possible wrong sentence/clause detection POS tagging).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Another reason hand ensure fair comparison Breck Baldwin's method, available us, hand-simulated (see 3.3).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evaluation indicated 83.6% success rate.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Baseline subject model tested data scored 33.9% recall 67.9% precision, whereas ""Baseline recent"" scored 66.7%."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Note ""Baseline subject"" assessed terms recall precision ""version"" robust: event subject available, able propose antecedent (the manual guide used evaluation text contained many im­ perative zero-subject sentences)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"second experiment evaluated ap­ proach point view also ""critical success rate""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"measure (Mitkov 1998b) applies anaphors ""ambiguous"" point view number gender (i.e. ""tough"" anaphors which, activating gender number filters, still one candidate antecedent) indicative performance antecedent indicators."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evaluation estab­ lished critical success rate 82%.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	case system failed anaphor antecedent sen­ tence preference given candidate preceding sentence.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"case cases suggest might worthwhile reconsider­ ing/refining weights indicator ""referential distance""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Similarly first evaluation, found robust approach successful sen­ tences complicated syntax - price pay ""convenience"" developing knowl­ edge-poor system."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	results experiment 1 experiment 2 summarised following (statistically) slightly representative figures.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	R ob ust aQ pr oa ch B el n e u b je ct B eli ne os ce nt Su cc es rat e (= Pr ec isi / ca ll) 8 9.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	7 % 31.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"55 % 48 .5 5 % 6 5 . 9 5 % lower figure ""Baseline subject"" corresponds ""recall"" higher figure- ""precision""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"regard ""discriminative power"" antecedent indicator ratio ""number successful antecedent identifications indicator applied""/""number applications indicator"" (for non-prepositional noun phrase definite­ ness penalising indicators, figure calcu­ lated ratio ""number unsuccessful antece­ dent identifications""/""number applications""), immediate reference emerges discrimi­ native indicator (100%), followed non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) referential distance (34.4%)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	rela­ tively low figures majority indicators regarded surprise: firstly, bear mind cases candidate picked (or rejected) antecedent ba­ sis applying number different indicators secondly, anaphors relatively high number candidates antecedent.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"terms frequency use (""number nonzero applications""/""number anaphors""), fre­ quently used indicator proved referential dis­ tance used 98.9% cases, followed term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) colloca­ tion (11.1%)."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	expected, frequent indica­ tors discriminative ones.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	3.3 Comparison similar approaches: compara­.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"tive evaluation Breck Baldwin's CogNIAC felt appropriate extend evaluation approach comparing Breck Baldwin's Cog­ NIAC (Baldwin 1997) approach features ""high precision coreference limited knowledge linguistics resources""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	reason approach Breck Baldwin's approach share common principles (both knowledge-poor use POS tagger provide input) therefore comparison would appropriate.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"Given approach robust returns an­ tecedent pronoun, order make comparison fair possible, used CogNIAC's ""resolve all"" version simulating manually training data used evaluation B above."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	CogNIAC successfully resolved pronouns 75% cases.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	result comparable results described (Baldwin 1997).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	training data genre technical manuals, rule 5 (see Baldwin 1997) frequently used (39% cases, 100% success), followed rule 8 (33% cases, 33% success), rule 7 (11%, 100%), rule (9%, 100%) rule 3 (7.4%, 100%).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	would fair say even though results show superiority approach training data used (the genre technical manuals), cannot generalised automatically genres unrestricted texts accurate picture, extensive tests necessary.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	"languages attractive feature NLP approach would language ""universality""."	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	acknowledge monolingual NLP approaches automatically transferable (with degree efficiency) languages, would highly desirable could done minimal adapta­ tion.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	used robust approach basis devel­ oping genre-specific reference resolution approach Polish.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	expected, preferences modified order fit specific features Polish (Mitkov & Stys 1997).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	time being, using scores Polish.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evaluation Polish based technical manuals available Internet (Internet Manual, 1994; Java Manual 1998).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	sample texts con­ tained 180 pronouns among 120 in­ stances exophoric reference (most zero pro­ nouns).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	robust approach adapted Polish demonstrated high success rate 93.3% resolv­ ing anaphors (with critical success rate 86.2%).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Similarly evaluation English, com­ pared approach Polish (i) Baseline Model discounts candidates basis agreement number gender and, still competing candidates, selects antecedent recent subject matching anaphor gender number (ii) Baseline Model checks agreement number gender and, still one candidate left, picks antecedent recent noun phrase agrees anaphor.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	preference-based approach showed clear su­ periority baseline models.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	first Base­ line Model (Baseline Subject) successful 23.7% cases, whereas second (Baseline Recent) success rate 68.4%.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	There­ fore, 93.3% success rate (see above) demon­ strates dramatic increase precision, due use antecedent tracking preferences.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	recently adapted approach Ara­ bic well (Mitkov & Belguith 1998).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	evalua­ tion, based 63 examples (anaphors) tech­ nical manual (Sony 1992), indicates success rate 95.2% (and critical success rate 89.3 %).	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	described robust, knowledge-poor ap­ proach pronoun resolution operates texts pre-processed part-of-speech tagger.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	Evaluation shows success rate 89.7% genre tech­ nical manuals least genre, approach appears successful similar methods.	0
Whereas knowledge-based systems like (Carbonell and Brown, 1988) and (Rich and LuperFoy, 1988) combining multiple resolution strategies are expenÂ­ sive in the cost of human effort at development time and limited ability to scale to new domains, more reÂ­ cent knowledge-poor approaches like (Kennedy and Boguraev, 1996) and (Mitkov, 1998) address the problem without sophisticated linguistic knowledge.	also adapted evaluated approach Polish (93.3 % success rate) Arabic (95.2% success rate).	0
